"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[129],{7098:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>i,metadata:()=>a,toc:()=>c});var t=r(4848),o=r(8453);const i={slug:"chapter-11-humanoid-kinematics-locomotion",title:"Chapter 11 - Humanoid Kinematics & Bipedal Locomotion",description:"Comprehensive guide to humanoid kinematics and bipedal locomotion for robotics",tags:["humanoid","kinematics","locomotion","bipedal","walking","robotics"]},s="\ud83d\udcda Chapter 11: Humanoid Kinematics & Bipedal Locomotion \ud83d\udcda",a={id:"part-5-advanced-humanoids/chapter-11-humanoid-kinematics-locomotion",title:"Chapter 11 - Humanoid Kinematics & Bipedal Locomotion",description:"Comprehensive guide to humanoid kinematics and bipedal locomotion for robotics",source:"@site/docusaurus/docs/part-5-advanced-humanoids/chapter-11-humanoid-kinematics-locomotion.md",sourceDirName:"part-5-advanced-humanoids",slug:"/part-5-advanced-humanoids/chapter-11-humanoid-kinematics-locomotion",permalink:"/Humanoid-Robotic-Book/docs/part-5-advanced-humanoids/chapter-11-humanoid-kinematics-locomotion",draft:!1,unlisted:!1,editUrl:"https://github.com/aamna847/Humanoid-Robotic-Book/edit/main/docusaurus/docs/part-5-advanced-humanoids/chapter-11-humanoid-kinematics-locomotion.md",tags:[{label:"humanoid",permalink:"/Humanoid-Robotic-Book/docs/tags/humanoid"},{label:"kinematics",permalink:"/Humanoid-Robotic-Book/docs/tags/kinematics"},{label:"locomotion",permalink:"/Humanoid-Robotic-Book/docs/tags/locomotion"},{label:"bipedal",permalink:"/Humanoid-Robotic-Book/docs/tags/bipedal"},{label:"walking",permalink:"/Humanoid-Robotic-Book/docs/tags/walking"},{label:"robotics",permalink:"/Humanoid-Robotic-Book/docs/tags/robotics"}],version:"current",frontMatter:{slug:"chapter-11-humanoid-kinematics-locomotion",title:"Chapter 11 - Humanoid Kinematics & Bipedal Locomotion",description:"Comprehensive guide to humanoid kinematics and bipedal locomotion for robotics",tags:["humanoid","kinematics","locomotion","bipedal","walking","robotics"]},sidebar:"tutorialSidebar",previous:{title:"Chapter 10 - Reinforcement Learning for Control",permalink:"/Humanoid-Robotic-Book/docs/part-4-ai-brain/chapter-10-reinforcement-learning-control"},next:{title:"Chapter 12 - VLA (Vision-Language-Action) & Conversational Robotics",permalink:"/Humanoid-Robotic-Book/docs/part-5-advanced-humanoids/chapter-12-vla-conversational-robotics"}},l={},c=[{value:"\ud83c\udfaf Learning Objectives \ud83c\udfaf",id:"-learning-objectives-",level:2},{value:"\ud83d\udc4b 11.1 Introduction to Humanoid Control Challenges \ud83d\udc4b",id:"-111-introduction-to-humanoid-control-challenges-",level:2},{value:"\u2139\ufe0f 11.1.1 Kinematic Complexity \u2139\ufe0f",id:"\u2139\ufe0f-1111-kinematic-complexity-\u2139\ufe0f",level:3},{value:"\ud83d\udccb 11.1.2 Balance and Stability Requirements \ud83d\udccb",id:"-1112-balance-and-stability-requirements-",level:3},{value:"\ud83c\udf9b\ufe0f 11.2 Bipedal Locomotion Control \ud83c\udf9b\ufe0f",id:"\ufe0f-112-bipedal-locomotion-control-\ufe0f",level:2},{value:"\u2139\ufe0f 11.2.1 Walking Pattern Generation \u2139\ufe0f",id:"\u2139\ufe0f-1121-walking-pattern-generation-\u2139\ufe0f",level:3},{value:"\ud83d\udd04 11.2.2 Advanced Locomotion Patterns \ud83d\udd04",id:"-1122-advanced-locomotion-patterns-",level:3},{value:"\ud83c\udf9b\ufe0f 11.3 Whole-Body Control \ud83c\udf9b\ufe0f",id:"\ufe0f-113-whole-body-control-\ufe0f",level:2},{value:"\ud83c\udf9b\ufe0f 11.3.1 Task-Priority Based Control \ud83c\udf9b\ufe0f",id:"\ufe0f-1131-task-priority-based-control-\ufe0f",level:3},{value:"\ud83c\udf9b\ufe0f 11.3.2 Model Predictive Control for Humanoids \ud83c\udf9b\ufe0f",id:"\ufe0f-1132-model-predictive-control-for-humanoids-\ufe0f",level:3},{value:"\ud83c\udfaf 11.4 Learning-Based Control \ud83c\udfaf",id:"-114-learning-based-control-",level:2},{value:"\ud83c\udfaf 11.4.1 Imitation Learning for Humanoid Movements \ud83c\udfaf",id:"-1141-imitation-learning-for-humanoid-movements-",level:3},{value:"\ud83c\udfaf 11.4.2 Reinforcement Learning for Humanoid Control \ud83c\udfaf",id:"-1142-reinforcement-learning-for-humanoid-control-",level:3},{value:"\ud83c\udf9b\ufe0f 11.5 Control Validation and Testing \ud83c\udf9b\ufe0f",id:"\ufe0f-115-control-validation-and-testing-\ufe0f",level:2},{value:"\ud83c\udfae 11.5.1 Simulation-Based Validation \ud83c\udfae",id:"-1151-simulation-based-validation-",level:3},{value:"\ud83e\udd16 11.6 Safety and Failsafe Systems \ud83e\udd16",id:"-116-safety-and-failsafe-systems-",level:2},{value:"\u2699\ufe0f 11.6.1 Emergency Response Systems \u2699\ufe0f",id:"\ufe0f-1161-emergency-response-systems-\ufe0f",level:3},{value:"\ud83d\udccf 11.6.2 Compliance and Safety Standards \ud83d\udccf",id:"-1162-compliance-and-safety-standards-",level:3},{value:"\ud83d\udcdd 11.7 Summary \ud83d\udcdd",id:"-117-summary-",level:2},{value:"\u2139\ufe0f Key Takeaways: \u2139\ufe0f",id:"\u2139\ufe0f-key-takeaways-\u2139\ufe0f",level:3},{value:"\ud83e\udd14 Knowledge Check \ud83e\udd14",id:"-knowledge-check-",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"-chapter-11-humanoid-kinematics--bipedal-locomotion-",children:"\ud83d\udcda Chapter 11: Humanoid Kinematics & Bipedal Locomotion \ud83d\udcda"}),"\n",(0,t.jsx)(n.h2,{id:"-learning-objectives-",children:"\ud83c\udfaf Learning Objectives \ud83c\udfaf"}),"\n",(0,t.jsx)(n.p,{children:"By the end of this chapter, students will be able to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Understand the unique challenges of controlling humanoid robots"}),"\n",(0,t.jsx)(n.li,{children:"Implement advanced control strategies for bipedal locomotion"}),"\n",(0,t.jsx)(n.li,{children:"Design balance and stability control systems"}),"\n",(0,t.jsx)(n.li,{children:"Integrate whole-body control approaches"}),"\n",(0,t.jsx)(n.li,{children:"Apply machine learning to humanoid movement learning"}),"\n",(0,t.jsx)(n.li,{children:"Evaluate and validate humanoid control systems"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"-111-introduction-to-humanoid-control-challenges-",children:"\ud83d\udc4b 11.1 Introduction to Humanoid Control Challenges \ud83d\udc4b"}),"\n",(0,t.jsx)(n.p,{children:"Humanoid robots, with their human-like form factor, present unique control challenges that differ significantly from simpler robotic platforms. These challenges stem from the robot's complex kinematic structure, underactuation, balance requirements, and the need to operate in human-designed environments."}),"\n",(0,t.jsx)(n.h3,{id:"\u2139\ufe0f-1111-kinematic-complexity-\u2139\ufe0f",children:"\u2139\ufe0f 11.1.1 Kinematic Complexity \u2139\ufe0f"}),"\n",(0,t.jsx)(n.p,{children:"Humanoid robots typically have 30+ degrees of freedom (DOF) distributed across legs, arms, and torso. This creates complex inverse kinematics problems where multiple joint configurations can achieve the same end-effector position."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import numpy as np\r\nimport roboticstoolbox as rtb\r\nfrom spatialmath import SE3\r\nimport matplotlib.pyplot as plt\r\n\r\nclass HumanoidKinematics:\r\n    def __init__(self):\r\n        # Simplified humanoid model with 12 DOF (6 per leg, 0 for upper body for simplicity)\r\n        # In practice, humanoids have many more DOF\r\n        self.dof = 12\r\n        \r\n        # Define joint limits\r\n        self.joint_limits = {\r\n            \'hip_yaw\': (-0.5, 0.5),\r\n            \'hip_roll\': (-0.5, 0.5),\r\n            \'hip_pitch\': (-1.0, 1.0),\r\n            \'knee\': (0.0, 2.0),\r\n            \'ankle_pitch\': (-0.5, 0.5),\r\n            \'ankle_roll\': (-0.5, 0.5)\r\n        }\r\n        \r\n        # Define link lengths (simplified)\r\n        self.link_lengths = {\r\n            \'thigh\': 0.4,  # meters\r\n            \'shin\': 0.4,   # meters\r\n        }\r\n    \r\n    def forward_kinematics(self, joint_angles):\r\n        """\r\n        Compute forward kinematics for simplified humanoid leg\r\n        joint_angles: array of 6 joint angles for one leg\r\n        Returns: end-effector position\r\n        """\r\n        # Simplified 3D forward kinematics for a leg with 6 DOF\r\n        # In practice, this would be much more complex\r\n        q = joint_angles\r\n        \r\n        # Compute positions of each joint in the chain\r\n        # This is a greatly simplified version - real implementations use rotation matrices\r\n        x = (self.link_lengths[\'thigh\'] * np.sin(q[2]) + \r\n             self.link_lengths[\'shin\'] * np.sin(q[2] + q[3]))\r\n        \r\n        y = 0  # Simplified, ignoring roll and yaw for this example\r\n        z = -(self.link_lengths[\'thigh\'] * np.cos(q[2]) + \r\n              self.link_lengths[\'shin\'] * np.cos(q[2] + q[3]))\r\n        \r\n        return np.array([x, y, z])\r\n    \r\n    def inverse_kinematics(self, target_pos, leg_offset=np.array([0, 0, 0])):\r\n        """\r\n        Compute inverse kinematics for reaching a target position\r\n        target_pos: desired end-effector position\r\n        leg_offset: offset from robot center to leg\r\n        Returns: joint angles to reach target position\r\n        """\r\n        # Simplified inverse kinematics for planar 2-link manipulator\r\n        # In practice, this would handle the full 6-DOF leg\r\n        target = target_pos - leg_offset\r\n        \r\n        # Calculate distance to target\r\n        dist = np.linalg.norm(target)\r\n        \r\n        # Leg lengths\r\n        l1 = self.link_lengths[\'thigh\']\r\n        l2 = self.link_lengths[\'shin\']\r\n        \r\n        # Check if target is reachable\r\n        if dist > (l1 + l2):\r\n            # Target out of reach, extend fully toward target\r\n            target = target * (l1 + l2) / dist\r\n        \r\n        if dist < abs(l1 - l2):\r\n            # Target inside workspace, move as close as possible\r\n            target = target * abs(l1 - l2) / dist\r\n        \r\n        # Inverse kinematics solution for 2-link planar manipulator\r\n        x, y, z = target\r\n        hip_pitch = np.arctan2(y, x)\r\n        \r\n        # Calculate leg angle in the xz plane\r\n        xz_dist = np.sqrt(x**2 + z**2)\r\n        \r\n        # Apply cosine rule for 2-link manipulator\r\n        cos_angle = (l1**2 + l2**2 - xz_dist**2) / (2 * l1 * l2)\r\n        cos_angle = np.clip(cos_angle, -1, 1)  # Clamp to valid range\r\n        knee_angle = np.pi - np.arccos(cos_angle)\r\n        \r\n        # Calculate hip angle\r\n        angle2 = np.arctan2(z, x)  # Angle from x-axis to target\r\n        angle1 = np.arccos((l1**2 + xz_dist**2 - l2**2) / (2 * l1 * xz_dist))\r\n        hip_angle = angle2 - angle1\r\n        \r\n        # Fill in remaining DOF with defaults (real implementation would be more complex)\r\n        joint_angles = np.zeros(6)\r\n        joint_angles[0] = 0  # hip_yaw (simplified)\r\n        joint_angles[1] = 0  # hip_roll (simplified) \r\n        joint_angles[2] = hip_angle  # hip_pitch\r\n        joint_angles[3] = knee_angle  # knee\r\n        joint_angles[4] = 0  # ankle_pitch (simplified)\r\n        joint_angles[5] = 0  # ankle_roll (simplified)\r\n        \r\n        return joint_angles\r\n\r\nclass AdvancedHumanoidController:\r\n    def __init__(self, robot_model):\r\n        self.robot = robot_model\r\n        self.kinematics = HumanoidKinematics()\r\n        self.balance_controller = BalanceController()\r\n        self.walk_engine = WalkEngine()\r\n        \r\n    def move_to_pose(self, target_pose):\r\n        """\r\n        Move the humanoid to a target pose while maintaining balance\r\n        target_pose: SE3 transformation matrix\r\n        """\r\n        # Plan full-body motion to achieve target pose\r\n        joint_angles = self.solve_full_body_IK(target_pose)\r\n        \r\n        # Execute motion while monitoring balance\r\n        self.execute_balanced_motion(joint_angles)\r\n    \r\n    def solve_full_body_IK(self, target_pose):\r\n        """Solve full-body inverse kinematics problem"""\r\n        # This would use advanced methods like:\r\n        # - Task-priority based IK\r\n        # - Whole-body IK solvers (e.g., KDL, Pinocchio)\r\n        # - Optimization-based approaches\r\n        \r\n        # For this example, we\'ll return a simplified solution\r\n        return np.zeros(self.robot.nq)  # Placeholder\r\n    \r\n    def execute_balanced_motion(self, joint_angles):\r\n        """Execute motion while maintaining balance"""\r\n        # Use the balance controller to modulate movements\r\n        balanced_angles = self.balance_controller.adjust_for_balance(joint_angles)\r\n        \r\n        # Send commands to robot\r\n        self.robot.set_joint_targets(balanced_angles)\n'})}),"\n",(0,t.jsx)(n.h3,{id:"-1112-balance-and-stability-requirements-",children:"\ud83d\udccb 11.1.2 Balance and Stability Requirements \ud83d\udccb"}),"\n",(0,t.jsx)(n.p,{children:"Unlike wheeled or tracked robots, humanoid robots must maintain balance on two points of contact or dynamically transition between balance states."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import numpy as np\r\nfrom scipy import signal\r\nimport matplotlib.pyplot as plt\r\n\r\nclass BalanceController:\r\n    def __init__(self, robot_mass=75.0, com_height=0.8):\r\n        self.robot_mass = robot_mass  # kg\r\n        self.com_height = com_height  # Center of mass height in meters\r\n        \r\n        # Control gains\r\n        self.k_p = 500  # Proportional gain for position control\r\n        self.k_d = 100  # Derivative gain for velocity control\r\n        \r\n        # Support polygon boundaries\r\n        self.foot_separation = 0.3  # Distance between feet in meters\r\n        \r\n        # Current state estimates\r\n        self.com_position = np.zeros(3)  # Center of mass position [x, y, z]\r\n        self.com_velocity = np.zeros(3)  # Center of mass velocity\r\n        self.zmp = np.zeros(2)  # Zero Moment Point [x, y]\r\n        \r\n        # ZMP tracking controller\r\n        self.zmp_controller = self._create_zmp_controller()\r\n        \r\n    def _create_zmp_controller(self):\r\n        """Create ZMP (Zero Moment Point) tracking controller"""\r\n        # Simple PID controller for ZMP tracking\r\n        # In practice, this would be more sophisticated\r\n        return {\r\n            \'kp\': 100.0,  # Proportional gain\r\n            \'ki\': 10.0,   # Integral gain  \r\n            \'kd\': 50.0,   # Derivative gain\r\n            \'integral_error\': 0,\r\n            \'prev_error\': 0\r\n        }\r\n    \r\n    def update_state(self, sensor_data):\r\n        """Update controller with current sensor data"""\r\n        # Extract center of mass information from sensor data\r\n        # This would come from IMU, encoders, and possibly vision\r\n        self.com_position = sensor_data.get(\'com_position\', self.com_position)\r\n        self.com_velocity = sensor_data.get(\'com_velocity\', self.com_velocity)\r\n        self.zmp = sensor_data.get(\'zmp\', self.zmp)\r\n    \r\n    def compute_balance_correction(self, target_zmp, dt):\r\n        """Compute balance corrections based on ZMP error"""\r\n        # Calculate error between current and target ZMP\r\n        zmp_error = target_zmp - self.zmp\r\n        \r\n        # ZMP controller (simplified PID)\r\n        controller = self.zmp_controller\r\n        \r\n        # Proportional component\r\n        p_term = controller[\'kp\'] * zmp_error\r\n        \r\n        # Integral component\r\n        controller[\'integral_error\'] += zmp_error * dt\r\n        i_term = controller[\'ki\'] * controller[\'integral_error\']\r\n        \r\n        # Derivative component\r\n        derivative_error = (zmp_error - controller[\'prev_error\']) / dt\r\n        d_term = controller[\'kd\'] * derivative_error\r\n        \r\n        controller[\'prev_error\'] = zmp_error\r\n        \r\n        # Total correction\r\n        correction = p_term + i_term + d_term\r\n        \r\n        return correction\r\n    \r\n    def adjust_for_balance(self, joint_commands):\r\n        """Adjust joint commands to maintain balance"""\r\n        # Calculate necessary adjustments based on current COM position\r\n        # and planned movement\r\n        adjustments = np.zeros_like(joint_commands)\r\n        \r\n        # This would involve more complex calculations in practice\r\n        # to maintain the robot\'s center of mass within the support polygon\r\n        \r\n        return joint_commands + adjustments\r\n    \r\n    def compute_support_polygon(self, left_foot_pos, right_foot_pos):\r\n        """Compute support polygon based on foot positions"""\r\n        # For two feet, this is the convex hull of both foot contact points\r\n        # Simplified as a rectangle for this example\r\n        foot_length = 0.2  # meters\r\n        foot_width = 0.1   # meters\r\n        \r\n        # Center points\r\n        center = (left_foot_pos + right_foot_pos) / 2\r\n        dx = right_foot_pos[0] - left_foot_pos[0]\r\n        dy = right_foot_pos[1] - left_foot_pos[1]\r\n        \r\n        # Support polygon vertices (simplified)\r\n        vertices = np.array([\r\n            [center[0] - foot_length/2, center[1] - foot_width],\r\n            [center[0] + foot_length/2, center[1] - foot_width],\r\n            [center[0] + foot_length/2, center[1] + foot_width],\r\n            [center[0] - foot_length/2, center[1] + foot_width]\r\n        ])\r\n        \r\n        # Add points for each foot\r\n        # Left foot\r\n        vertices = np.vstack([\r\n            vertices,\r\n            [\r\n                [left_foot_pos[0] - foot_length/2, left_foot_pos[1] - foot_width/2],\r\n                [left_foot_pos[0] + foot_length/2, left_foot_pos[1] - foot_width/2],\r\n                [left_foot_pos[0] + foot_length/2, left_foot_pos[1] + foot_width/2],\r\n                [left_foot_pos[0] - foot_length/2, left_foot_pos[1] + foot_width/2]\r\n            ]\r\n        ])\r\n        \r\n        # Right foot\r\n        vertices = np.vstack([\r\n            vertices,\r\n            [\r\n                [right_foot_pos[0] - foot_length/2, right_foot_pos[1] - foot_width/2],\r\n                [right_foot_pos[0] + foot_length/2, right_foot_pos[1] - foot_width/2],\r\n                [right_foot_pos[0] + foot_length/2, right_foot_pos[1] + foot_width/2],\r\n                [right_foot_pos[0] - foot_length/2, right_foot_pos[1] + foot_width/2]\r\n            ]\r\n        ])\r\n        \r\n        return vertices\r\n    \r\n    def is_balanced(self, com_pos, support_polygon):\r\n        """Check if center of mass is within support polygon"""\r\n        # Simplified 2D check (x, y plane)\r\n        # In practice, this would use more sophisticated geometric methods\r\n        com_xy = com_pos[:2]\r\n        \r\n        # Check if point is inside polygon (ray casting algorithm - simplified)\r\n        x, y = com_xy[0], com_xy[1]\r\n        \r\n        # For this example, we\'ll use a bounding box check\r\n        min_x = np.min(support_polygon[:, 0])\r\n        max_x = np.max(support_polygon[:, 0])\r\n        min_y = np.min(support_polygon[:, 1])\r\n        max_y = np.max(support_polygon[:, 1])\r\n        \r\n        return (min_x <= x <= max_x) and (min_y <= y <= max_y)\r\n\r\nclass ZMPCalculator:\r\n    def __init__(self, gravity=9.81):\r\n        self.g = gravity\r\n    \r\n    def compute_zmp_simple(self, com_pos, com_acc):\r\n        """Compute ZMP from center of mass position and acceleration"""\r\n        # ZMP_x = CoM_x - (CoM_z - foot_z) / g * CoM_acc_x\r\n        # ZMP_y = CoM_y - (CoM_z - foot_z) / g * CoM_acc_y\r\n        \r\n        foot_height = 0  # Simplified: foot at z=0\r\n        zmp_x = com_pos[0] - (com_pos[2] - foot_height) / self.g * com_acc[0]\r\n        zmp_y = com_pos[1] - (com_pos[2] - foot_height) / self.g * com_acc[1]\r\n        \r\n        return np.array([zmp_x, zmp_y])\n'})}),"\n",(0,t.jsx)(n.h2,{id:"\ufe0f-112-bipedal-locomotion-control-\ufe0f",children:"\ud83c\udf9b\ufe0f 11.2 Bipedal Locomotion Control \ud83c\udf9b\ufe0f"}),"\n",(0,t.jsx)(n.h3,{id:"\u2139\ufe0f-1121-walking-pattern-generation-\u2139\ufe0f",children:"\u2139\ufe0f 11.2.1 Walking Pattern Generation \u2139\ufe0f"}),"\n",(0,t.jsx)(n.p,{children:"Generating stable walking patterns for bipedal robots requires careful consideration of balance, momentum, and ground contact forces."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import numpy as np\r\nfrom scipy import interpolate\r\nimport matplotlib.pyplot as plt\r\n\r\nclass WalkEngine:\r\n    def __init__(self, step_length=0.3, step_height=0.05, step_time=0.8):\r\n        self.step_length = step_length  # meters\r\n        self.step_height = step_height  # meters\r\n        self.step_time = step_time      # seconds\r\n        \r\n        # Walking parameters\r\n        self.stride = step_length\r\n        self.foot_lift = step_height\r\n        self.cycle_time = step_time\r\n        \r\n        # Gait phase tracking\r\n        self.phase = 0  # 0.0 to 1.0\r\n        self.swing_leg = \'left\'  # Which leg is swinging\r\n        self.double_support_ratio = 0.2  # 20% of step cycle in double support\r\n        \r\n        # Store trajectory\r\n        self.trajectory = []\r\n        \r\n    def generate_foot_trajectory(self, start_pos, goal_pos, current_time=0):\r\n        """Generate smooth trajectory for foot movement"""\r\n        # Define key frames for the foot trajectory\r\n        # 1. Lift foot from ground\r\n        # 2. Move foot forward in arc\r\n        # 3. Lower foot to ground\r\n        \r\n        # Create time array for the step\r\n        t_step = np.linspace(0, self.step_time, num=100)\r\n        \r\n        # X trajectory: simple linear movement\r\n        x_traj = np.linspace(start_pos[0], goal_pos[0], num=100)\r\n        \r\n        # Y trajectory: adjust Y position if changing stance legs\r\n        y_start, y_goal = start_pos[1], goal_pos[1]\r\n        y_traj = np.linspace(y_start, y_goal, num=100)\r\n        \r\n        # Z trajectory: parabolic arc for foot lift\r\n        z_lift = np.zeros_like(t_step)\r\n        \r\n        # Calculate when to lift and lower foot (single vs double support)\r\n        lift_start = self.double_support_ratio * self.step_time / 2\r\n        lift_end = self.step_time - lift_start\r\n        \r\n        for i, t in enumerate(t_step):\r\n            if t < lift_start or t > lift_end:\r\n                # Foot on ground\r\n                z_lift[i] = 0.0\r\n            else:\r\n                # Foot in swing phase - lift in parabolic arc\r\n                t_lift = (t - lift_start) / (lift_end - lift_start)  # Normalize to [0,1]\r\n                \r\n                # Parabolic trajectory: 4 * h * t * (1-t) for normalized t\r\n                z_lift[i] = 4 * self.step_height * t_lift * (1 - t_lift)\r\n        \r\n        # Combine into trajectory\r\n        trajectory = np.column_stack([x_traj, y_traj, z_lift])\r\n        \r\n        return trajectory, t_step\r\n    \r\n    def generate_com_trajectory(self, walking_speed):\r\n        """Generate Center of Mass trajectory for stable walking"""\r\n        # Use inverted pendulum model for CoM trajectory\r\n        # This creates a stable walking pattern by moving CoM appropriately\r\n        \r\n        # Walking parameters\r\n        step_time = self.step_time\r\n        step_length = self.step_length\r\n        \r\n        # Time vector\r\n        t = np.linspace(0, step_time, num=100)\r\n        \r\n        # Generate CoM trajectory in X direction (forward movement)\r\n        com_x = np.linspace(0, walking_speed * step_time, num=100)\r\n        \r\n        # Generate CoM trajectory in Z direction (up and down movement)\r\n        # Humans naturally move CoM up and down to save energy\r\n        com_z = 0.8 + 0.02 * np.sin(2 * np.pi * t / step_time)  # Small oscillation\r\n        \r\n        # Generate CoM trajectory in Y direction (lateral movement)\r\n        # Shift CoM toward stance leg to maintain balance\r\n        com_y = 0.0  # For this example, simplified\r\n        if self.swing_leg == \'right\':\r\n            # Shift CoM slightly to left (stance leg side)\r\n            com_y = -0.05 * np.ones_like(t)\r\n        else:\r\n            # Shift CoM slightly to right (stance leg side)\r\n            com_y = 0.05 * np.ones_like(t)\r\n        \r\n        return np.column_stack([com_x, com_y, com_z]), t\r\n    \r\n    def update_walking_phase(self, dt):\r\n        """Update the walking phase based on time"""\r\n        self.phase += dt / self.step_time\r\n        \r\n        # Keep phase in [0, 1]\r\n        if self.phase >= 1.0:\r\n            self.phase = 0.0\r\n            # Switch swing leg\r\n            self.swing_leg = \'right\' if self.swing_leg == \'left\' else \'left\'\r\n    \r\n    def is_double_support_phase(self):\r\n        """Check if currently in double support phase"""\r\n        # Double support at beginning and end of step cycle\r\n        return (self.phase < self.double_support_ratio / 2 or \r\n                self.phase > 1.0 - self.double_support_ratio / 2)\r\n\r\nclass WalkingController:\r\n    def __init__(self, walk_engine, balance_controller):\r\n        self.walk_engine = walk_engine\r\n        self.balance_controller = balance_controller\r\n        \r\n        # Store previous step information\r\n        self.left_foot_pos = np.array([0.0, 0.15, 0.0])   # Starting position\r\n        self.right_foot_pos = np.array([0.0, -0.15, 0.0])  # Starting position\r\n        \r\n        # Walking state\r\n        self.target_velocity = np.array([0.0, 0.0, 0.0])  # Target walking velocity\r\n        self.is_walking = False\r\n        \r\n    def start_walking(self, velocity):\r\n        """Start walking with specified velocity"""\r\n        self.target_velocity = velocity\r\n        self.is_walking = True\r\n    \r\n    def stop_walking(self):\r\n        """Stop walking"""\r\n        self.target_velocity = np.array([0.0, 0.0, 0.0])\r\n        self.is_walking = False\r\n    \r\n    def compute_walking_step(self, dt):\r\n        """Compute the next step in walking"""\r\n        if not self.is_walking:\r\n            return None\r\n        \r\n        # Update walking phase\r\n        self.walk_engine.update_walking_phase(dt)\r\n        \r\n        # Determine which foot to move based on walking phase\r\n        if self.walk_engine.swing_leg == \'left\':\r\n            stance_foot_pos = self.right_foot_pos\r\n            swing_foot_pos = self.left_foot_pos\r\n        else:\r\n            stance_foot_pos = self.left_foot_pos\r\n            swing_foot_pos = self.right_foot_pos\r\n        \r\n        # Calculate next swing foot position\r\n        # Move forward by step length in the walking direction\r\n        goal_offset = self.target_velocity * self.walk_engine.step_time\r\n        goal_pos = stance_foot_pos + goal_offset\r\n        \r\n        # Generate foot trajectory\r\n        trajectory, time_steps = self.walk_engine.generate_foot_trajectory(\r\n            swing_foot_pos, goal_pos\r\n        )\r\n        \r\n        # Calculate CoM trajectory for stability\r\n        com_trajectory, com_time = self.walk_engine.generate_com_trajectory(\r\n            np.linalg.norm(self.target_velocity)\r\n        )\r\n        \r\n        # Return computed trajectories\r\n        return {\r\n            \'swing_foot_trajectory\': trajectory,\r\n            \'com_trajectory\': com_trajectory,\r\n            \'step_timing\': time_steps,\r\n            \'stance_foot_pos\': stance_foot_pos\r\n        }\r\n    \r\n    def adjust_step_for_balance(self, step_data, sensor_data):\r\n        """Adjust step parameters based on balance information"""\r\n        # This would modify the planned step based on current stability\r\n        # For example, if the robot is leaning too far, adjust foot placement\r\n        \r\n        # Extract current state\r\n        current_com = sensor_data.get(\'com_position\', np.zeros(3))\r\n        current_zmp = sensor_data.get(\'zmp\', np.zeros(2))\r\n        \r\n        # Adjust goal position based on balance state\r\n        adjusted_data = step_data.copy()\r\n        \r\n        # Example: if robot is leaning right, step to the right more\r\n        if current_com[1] > 0.05:  # Leaning right\r\n            adjustment = np.array([0.0, -0.02, 0.0])  # Step more left\r\n            adjusted_data[\'swing_foot_trajectory\'] += adjustment\r\n        \r\n        return adjusted_data\n'})}),"\n",(0,t.jsx)(n.h3,{id:"-1122-advanced-locomotion-patterns-",children:"\ud83d\udd04 11.2.2 Advanced Locomotion Patterns \ud83d\udd04"}),"\n",(0,t.jsx)(n.p,{children:"Beyond basic walking, humanoid robots need to handle various locomotion patterns:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"class LocomotionPatternGenerator:\r\n    def __init__(self, robot_properties):\r\n        self.properties = robot_properties\r\n        self.current_gait = 'walk'\r\n        \r\n    def generate_walk_pattern(self, speed, direction):\r\n        \"\"\"Generate walking pattern at specified speed and direction\"\"\"\r\n        # For this example, we'll use the WalkEngine\r\n        # In practice, this would generate more sophisticated patterns\r\n        walk_engine = WalkEngine()\r\n        return {\r\n            'pattern_type': 'walk',\r\n            'speed': speed,\r\n            'direction': direction,\r\n            'engine': walk_engine\r\n        }\r\n    \r\n    def generate_walk_pattern(self, speed, direction):\r\n        \"\"\"Generate walking pattern at specified speed and direction\"\"\"\r\n        # Calculate step parameters based on desired speed\r\n        step_length = np.clip(speed * 0.6, 0.1, 0.5)  # Step length proportional to speed\r\n        step_time = max(0.5, 1.0 - speed * 0.2)       # Faster steps for higher speeds\r\n        \r\n        # Create walk engine with calculated parameters\r\n        walk_engine = WalkEngine(\r\n            step_length=step_length,\r\n            step_height=0.05,\r\n            step_time=step_time\r\n        )\r\n        \r\n        return {\r\n            'pattern_type': 'walk',\r\n            'speed': speed,\r\n            'direction': direction,\r\n            'engine': walk_engine,\r\n            'step_length': step_length,\r\n            'step_time': step_time\r\n        }\r\n    \r\n    def generate_run_pattern(self, speed, direction):\r\n        \"\"\"Generate running pattern at specified speed and direction\"\"\"\r\n        # Running has different parameters than walking\r\n        # - Higher step frequency\r\n        # - Greater step length\r\n        # - Aerial phase\r\n        \r\n        # For simplicity in this example\r\n        step_length = speed * 1.0  # Longer steps for running\r\n        step_time = max(0.2, 0.8 - speed * 0.3)  # Faster steps\r\n        flight_time_ratio = 0.2  # 20% of step cycle in flight phase\r\n        \r\n        return {\r\n            'pattern_type': 'run',\r\n            'speed': speed,\r\n            'direction': direction,\r\n            'step_length': step_length,\r\n            'step_time': step_time,\r\n            'flight_time_ratio': flight_time_ratio\r\n        }\r\n    \r\n    def generate_turn_pattern(self, angle, direction):\r\n        \"\"\"Generate turning pattern\"\"\"\r\n        # Turning requires different foot placement and CoM movement\r\n        # This is simplified for this example\r\n        \r\n        return {\r\n            'pattern_type': 'turn',\r\n            'angle': angle,\r\n            'direction': direction,  # 'left' or 'right'\r\n            'step_asymmetry': abs(angle) * 0.1  # More asymmetric for larger turns\r\n        }\r\n    \r\n    def generate_climb_pattern(self, step_height):\r\n        \"\"\"Generate stair climbing pattern\"\"\"\r\n        # Climbing requires extra vertical movement\r\n        step_length = 0.2  # Shorter steps for stability\r\n        step_height = max(0.15, step_height)  # Minimum step height\r\n        \r\n        return {\r\n            'pattern_type': 'climb',\r\n            'step_height': step_height,\r\n            'step_length': step_length,\r\n            'vertical_clearance': step_height + 0.05  # Extra clearance\r\n        }\r\n\r\nclass GaitAdaptationController:\r\n    def __init__(self, locomotion_generator, terrain_classifier):\r\n        self.generator = locomotion_generator\r\n        self.terrain_classifier = terrain_classifier\r\n        self.current_pattern = None\r\n        \r\n    def adapt_gait_to_terrain(self, terrain_type):\r\n        \"\"\"Adapt gait pattern based on terrain type\"\"\"\r\n        if terrain_type == 'flat':\r\n            # Use normal walking gait\r\n            pattern = self.generator.generate_walk_pattern(speed=0.5, direction='forward')\r\n        elif terrain_type == 'rough':\r\n            # Use more cautious gait with smaller steps\r\n            pattern = self.generator.generate_walk_pattern(speed=0.3, direction='forward')\r\n            pattern['step_length'] *= 0.7  # Shorter steps on rough terrain\r\n            pattern['step_height'] += 0.02  # Higher foot clearance\r\n        elif terrain_type == 'stairs':\r\n            # Use climbing pattern\r\n            pattern = self.generator.generate_climb_pattern(step_height=0.17)  # Standard stair height\r\n        elif terrain_type == 'narrow':\r\n            # Use gait with feet closer together\r\n            pattern = self.generator.generate_walk_pattern(speed=0.4, direction='forward')\r\n            # Adjust foot placement to be more centered\r\n        else:\r\n            # Default to normal walking\r\n            pattern = self.generator.generate_walk_pattern(speed=0.5, direction='forward')\r\n        \r\n        self.current_pattern = pattern\r\n        return pattern\r\n    \r\n    def adapt_gait_to_disturbance(self, disturbance_type, magnitude):\r\n        \"\"\"Adapt gait in response to external disturbances\"\"\"\r\n        if not self.current_pattern:\r\n            return\r\n        \r\n        if disturbance_type == 'push':\r\n            # If pushed, widen stance and reduce speed\r\n            self.current_pattern['step_length'] *= 0.8\r\n            self.current_pattern['speed'] = max(0.1, self.current_pattern['speed'] * 0.7)\r\n        elif disturbance_type == 'slip':\r\n            # If slipping, increase ground clearance and slow down\r\n            self.current_pattern['step_height'] += 0.02\r\n            self.current_pattern['speed'] = max(0.1, self.current_pattern['speed'] * 0.5)\r\n        \r\n        return self.current_pattern\n"})}),"\n",(0,t.jsx)(n.h2,{id:"\ufe0f-113-whole-body-control-\ufe0f",children:"\ud83c\udf9b\ufe0f 11.3 Whole-Body Control \ud83c\udf9b\ufe0f"}),"\n",(0,t.jsx)(n.h3,{id:"\ufe0f-1131-task-priority-based-control-\ufe0f",children:"\ud83c\udf9b\ufe0f 11.3.1 Task-Priority Based Control \ud83c\udf9b\ufe0f"}),"\n",(0,t.jsx)(n.p,{children:"Whole-body control coordinates multiple tasks with different priorities to achieve complex behaviors:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import numpy as np\r\nfrom scipy.linalg import block_diag\r\n\r\nclass WholeBodyController:\r\n    def __init__(self, robot_model, num_joints):\r\n        self.model = robot_model\r\n        self.n_joints = num_joints\r\n        \r\n        # Control hierarchy\r\n        self.tasks = []\r\n        self.priorities = []\r\n        \r\n    def add_task(self, task_jacobian, task_error, priority, weight=1.0):\r\n        """\r\n        Add a control task to the hierarchy\r\n        task_jacobian: Jacobian matrix for the task (3xN or 6xN for spatial task)\r\n        task_error: Error vector for the task (3x1 or 6x1)\r\n        priority: Priority level (0 = highest priority, higher numbers = lower priority)\r\n        weight: Weight for this task within its priority level\r\n        """\r\n        task = {\r\n            \'jacobian\': task_jacobian,\r\n            \'error\': task_error,\r\n            \'priority\': priority,\r\n            \'weight\': weight\r\n        }\r\n        \r\n        self.tasks.append(task)\r\n        self.priorities.append(priority)\r\n        \r\n        # Keep tasks sorted by priority\r\n        sorted_indices = sorted(range(len(self.priorities)), \r\n                                key=lambda i: self.priorities[i])\r\n        \r\n        self.tasks = [self.tasks[i] for i in sorted_indices]\r\n        self.priorities = [self.priorities[i] for i in sorted_indices]\r\n    \r\n    def compute_command(self):\r\n        """\r\n        Compute joint velocity commands using task-priority based control\r\n        Based on the stack of tasks (Saab et al. approach)\r\n        """\r\n        # Initialize nullspace projection matrix as identity\r\n        N_current = np.eye(self.n_joints)\r\n        joint_velocity = np.zeros(self.n_joints)\r\n        \r\n        # Process tasks in priority order\r\n        for task in self.tasks:\r\n            # Project task jacobian onto current nullspace\r\n            A_proj = task[\'jacobian\'] @ N_current\r\n            \r\n            # Compute damped pseudo-inverse\r\n            # J# = W^-1 * J^T * (J * W^-1 * J^T + \u03bb^2 * I)^-1\r\n            # For simplicity, using standard damped inverse\r\n            damping = 1e-4\r\n            J_damped_inv = np.linalg.pinv(\r\n                A_proj @ A_proj.T + damping * np.eye(A_proj.shape[0])\r\n            ) @ A_proj\r\n            \r\n            # Compute desired task velocity\r\n            task_vel = task[\'error\'] * task[\'weight\']  # Proportional control\r\n            \r\n            # Compute joint velocity contribution\r\n            delta_q = J_damped_inv @ task_vel\r\n            \r\n            # Add to total velocity (projected onto current nullspace)\r\n            joint_velocity += N_current @ delta_q\r\n            \r\n            # Update nullspace projection matrix\r\n            # N_new = N_current * (I - J_damped_inv * A_proj)\r\n            N_current = N_current @ (np.eye(self.n_joints) - \r\n                                   np.linalg.pinv(A_proj, rcond=1e-4) @ A_proj)\r\n        \r\n        return joint_velocity\r\n    \r\n    def compute_com_balance_task(self, desired_com_pos, current_com_pos, \r\n                                 com_jacobian):\r\n        """Create a center of mass balance task"""\r\n        com_error = desired_com_pos - current_com_pos\r\n        \r\n        # Add this task with high priority\r\n        self.add_task(com_jacobian, com_error, priority=0, weight=2.0)\r\n    \r\n    def compute_foot_placement_task(self, desired_foot_pos, current_foot_pos,\r\n                                    foot_jacobian):\r\n        """Create a foot placement task"""\r\n        foot_error = desired_foot_pos - current_foot_pos\r\n        \r\n        # Add this task with medium priority\r\n        self.add_task(foot_jacobian, foot_error, priority=1, weight=1.5)\r\n    \r\n    def compute_arm_posture_task(self, desired_joint_angles, current_joint_angles,\r\n                                 arm_jacobian):\r\n        """Create an arm posture task"""\r\n        posture_error = desired_joint_angles - current_joint_angles\r\n        \r\n        # Add this task with low priority\r\n        self.add_task(arm_jacobian, posture_error, priority=2, weight=0.5)\r\n\r\nclass OperationalSpaceController:\r\n    def __init__(self, robot_model, num_joints):\r\n        self.model = robot_model\r\n        self.n_joints = num_joints\r\n        \r\n        # Mass matrix and other model parameters will be computed as needed\r\n        self.M_inv = None  # Inverse of mass matrix\r\n        self.C = None      # Coriolis and centrifugal forces\r\n        self.G = None      # Gravity forces\r\n        \r\n    def compute_operational_force(self, task_jacobian, desired_accel, \r\n                                  current_pos, desired_pos, current_vel, \r\n                                  desired_vel, kp=100, kd=20):\r\n        """\r\n        Compute operational space force for a task\r\n        """\r\n        # Position error\r\n        pos_error = desired_pos - current_pos\r\n        \r\n        # Velocity error  \r\n        vel_error = desired_vel - current_vel\r\n        \r\n        # Desired acceleration in operational space\r\n        op_acc_desired = (kp * pos_error + \r\n                         kd * vel_error + \r\n                         desired_accel)\r\n        \r\n        # Operational space mass matrix\r\n        # Lambda = (J * M^-1 * J^T)^-1\r\n        if self.M_inv is None:\r\n            # Compute inverse mass matrix (would come from robot dynamics)\r\n            self.M_inv = np.eye(self.n_joints)  # Placeholder\r\n        \r\n        J = task_jacobian\r\n        lambda_op = np.linalg.inv(J @ self.M_inv @ J.T)\r\n        \r\n        # Operational space force\r\n        F_op = lambda_op @ op_acc_desired\r\n        \r\n        # Convert to joint space force\r\n        tau = J.T @ F_op\r\n        \r\n        return tau\r\n    \r\n    def compute_walking_controller(self, left_foot_pos, right_foot_pos, \r\n                                   com_pos, com_vel, dt):\r\n        """\r\n        Compute control forces for walking\r\n        """\r\n        # Define desired trajectories\r\n        # This would come from gait planner\r\n        \r\n        # Compute ZMP-based balance control\r\n        zmp_desired = self.compute_zmp_reference(left_foot_pos, right_foot_pos)\r\n        zmp_current = self.compute_current_zmp(com_pos, com_vel)\r\n        \r\n        # Balance control\r\n        zmp_error = zmp_desired - zmp_current[:2]  # Only X,Y components\r\n        \r\n        # Convert balance error to CoM acceleration command\r\n        com_acc_cmd = self.balance_control(zmp_error)\r\n        \r\n        # Compute operational forces for each foot and CoM\r\n        left_foot_jac = self.compute_jacobian(\'left_foot\')\r\n        right_foot_jac = self.compute_jacobian(\'right_foot\')\r\n        com_jac = self.compute_jacobian(\'com\')\r\n        \r\n        # Left foot: try to maintain contact or move to next position\r\n        left_foot_tau = self.compute_operational_force(\r\n            left_foot_jac, \r\n            desired_accel=np.zeros(3),  # Keep at current position\r\n            current_pos=left_foot_pos[:3], \r\n            desired_pos=left_foot_pos[:3],\r\n            current_vel=np.zeros(3),  # Assume at rest for simplicity\r\n            desired_vel=np.zeros(3),\r\n            kp=500, kd=100\r\n        )\r\n        \r\n        # CoM: track balance trajectory\r\n        com_tau = self.compute_operational_force(\r\n            com_jac,\r\n            desired_accel=com_acc_cmd,\r\n            current_pos=com_pos,\r\n            desired_pos=com_pos + com_vel * dt + 0.5 * com_acc_cmd * dt**2,\r\n            current_vel=com_vel,\r\n            desired_vel=com_vel + com_acc_cmd * dt,\r\n            kp=100, kd=20\r\n        )\r\n        \r\n        return left_foot_tau + com_tau  # Combine torques\r\n    \r\n    def compute_jacobian(self, link_name):\r\n        """Compute Jacobian matrix for a given link"""\r\n        # This would interface with robot dynamics library\r\n        # For simplicity, return a placeholder\r\n        if link_name == \'left_foot\':\r\n            return np.random.rand(6, self.n_joints)  # Placeholder (6 for spatial, N for joints)\r\n        elif link_name == \'right_foot\':\r\n            return np.random.rand(6, self.n_joints)\r\n        elif link_name == \'com\':\r\n            return np.random.rand(3, self.n_joints)  # 3 for CoM position\r\n        else:\r\n            return np.zeros((6, self.n_joints))\r\n    \r\n    def compute_zmp_reference(self, left_foot_pos, right_foot_pos):\r\n        """Compute reference ZMP position based on foot positions"""\r\n        # For double support, ZMP is between feet\r\n        # For single support, ZMP is under stance foot\r\n        support_center = (left_foot_pos + right_foot_pos) / 2\r\n        return support_center[:2]  # X,Y of support polygon center\r\n    \r\n    def compute_current_zmp(self, com_pos, com_vel):\r\n        """Compute current ZMP from CoM state"""\r\n        # ZMP_x = CoM_x - (CoM_z - h) / g * CoM_acc_x\r\n        # We\'ll approximate acceleration from velocity\r\n        g = 9.81  # Gravity constant\r\n        h = com_pos[2]  # Approximate CoM height\r\n        \r\n        # For simplicity, using finite difference for acceleration\r\n        # In practice, this would come from IMU or state estimation\r\n        zmp_x = com_pos[0]  # Rough approximation\r\n        zmp_y = com_pos[1]\r\n        \r\n        return np.array([zmp_x, zmp_y, 0.0])\r\n    \r\n    def balance_control(self, zmp_error):\r\n        """Compute CoM acceleration command for balance"""\r\n        # Simple PD controller for ZMP error\r\n        kp = 50.0\r\n        kd = 10.0\r\n        \r\n        # Convert ZMP error to CoM acceleration command\r\n        com_acc_cmd = kp * zmp_error  # Proportional to error\r\n        \r\n        return np.array([com_acc_cmd[0], com_acc_cmd[1], 0.0])\n'})}),"\n",(0,t.jsx)(n.h3,{id:"\ufe0f-1132-model-predictive-control-for-humanoids-\ufe0f",children:"\ud83c\udf9b\ufe0f 11.3.2 Model Predictive Control for Humanoids \ud83c\udf9b\ufe0f"}),"\n",(0,t.jsx)(n.p,{children:"Model predictive control (MPC) is particularly valuable for humanoid robots due to its ability to handle constraints:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import numpy as np\r\nfrom scipy.optimize import minimize\r\nimport cvxpy as cp\r\n\r\nclass MPCBalanceController:\r\n    def __init__(self, prediction_horizon=20, dt=0.01, com_height=0.8):\r\n        self.N = prediction_horizon  # Number of prediction steps\r\n        self.dt = dt                 # Time step\r\n        self.h = com_height          # CoM height\r\n        \r\n        # System matrices for inverted pendulum model\r\n        # CoM dynamics: x(k+1) = A*x(k) + B*u(k)\r\n        # where x = [px, py, vx, vy] (position and velocity of CoM)\r\n        # and u = [ux, uy] (CoM acceleration)\r\n        self.A = np.array([\r\n            [1, 0, dt, 0],\r\n            [0, 1, 0, dt],\r\n            [0, 0, 1, 0],\r\n            [0, 0, 0, 1]\r\n        ])\r\n        \r\n        self.B = np.array([\r\n            [0.5*dt**2, 0],\r\n            [0, 0.5*dt**2],\r\n            [dt, 0],\r\n            [0, dt]\r\n        ])\r\n    \r\n    def compute_optimal_control(self, current_state, reference_trajectory, \r\n                                support_feet_positions):\r\n        """\r\n        Compute optimal CoM trajectory using MPC\r\n        current_state: [px, py, vx, vy] - current CoM state\r\n        reference_trajectory: shape (N, 4) - desired CoM states over horizon\r\n        support_feet_positions: list of [x, y] positions for each time step\r\n        """\r\n        N = self.N\r\n        \r\n        # Decision variables: CoM states and accelerations over the horizon\r\n        X = cp.Variable((N+1, 4))  # State trajectory [px, py, vx, vy]\r\n        U = cp.Variable((N, 2))    # Control trajectory [ux, uy] (acceleration)\r\n        \r\n        # Objective function: track reference trajectory with minimal control effort\r\n        cost = 0\r\n        for k in range(N):\r\n            # State tracking cost\r\n            cost += cp.sum_squares(X[k, :] - reference_trajectory[k, :])\r\n            \r\n            # Control effort cost\r\n            cost += 0.1 * cp.sum_squares(U[k, :])\r\n        \r\n        # Add terminal cost\r\n        cost += 10 * cp.sum_squares(X[N, :] - reference_trajectory[-1, :])\r\n        \r\n        # Constraints\r\n        constraints = []\r\n        \r\n        # Initial state constraint\r\n        constraints.append(X[0, :] == current_state)\r\n        \r\n        # System dynamics\r\n        for k in range(N):\r\n            constraints.append(X[k+1, :] == self.A @ X[k, :] + self.B @ U[k, :])\r\n        \r\n        # ZMP stability constraints\r\n        # ZMP must be inside support polygon at each time step\r\n        g = 9.81\r\n        for k in range(N):\r\n            # Compute ZMP from CoM state: zmp = [px, py] - h/g * [vx, vy]\r\n            zmp_x = X[k, 0] - (self.h / g) * X[k, 2]\r\n            zmp_y = X[k, 1] - (self.h / g) * X[k, 3]\r\n            \r\n            # For this example, assume rectangular support polygon around foot positions\r\n            # In practice, this would check if ZMP is inside convex hull of contact points\r\n            foot_pos = support_feet_positions[min(k, len(support_feet_positions)-1)]\r\n            \r\n            # Assume support polygon of 10cm x 20cm around foot center\r\n            constraints.append(zmp_x >= foot_pos[0] - 0.05)\r\n            constraints.append(zmp_x <= foot_pos[0] + 0.05)\r\n            constraints.append(zmp_y >= foot_pos[1] - 0.10)\r\n            constraints.append(zmp_y <= foot_pos[1] + 0.10)\r\n        \r\n        # Control limits (maximum CoM acceleration)\r\n        for k in range(N):\r\n            constraints.append(cp.norm(U[k, :], \'inf\') <= 5.0)  # Max 5 m/s\xb2 acceleration\r\n        \r\n        # Solve optimization problem\r\n        problem = cp.Problem(cp.Minimize(cost), constraints)\r\n        \r\n        try:\r\n            problem.solve(solver=cp.ECOS, verbose=False)\r\n            \r\n            if problem.status not in ["infeasible", "unbounded"]:\r\n                # Return first control command and predicted trajectory\r\n                return U[0, :].value, X.value\r\n            else:\r\n                print(f"MPC problem status: {problem.status}")\r\n                return np.zeros(2), np.tile(current_state, (N+1, 1))\r\n        except Exception as e:\r\n            print(f"MPC optimization error: {e}")\r\n            return np.zeros(2), np.tile(current_state, (N+1, 1))\r\n\r\nclass PredictiveWalkingController:\r\n    def __init__(self, mpc_controller, walk_engine):\r\n        self.mpc = mpc_controller\r\n        self.walk_engine = walk_engine\r\n        self.footstep_planner = FootstepPlanner()\r\n        \r\n    def plan_footsteps(self, walk_command):\r\n        """Plan future footsteps based on walking command"""\r\n        # This would use path planning and gait analysis\r\n        # For this example, we\'ll generate a simple sequence\r\n        \r\n        current_pos = np.array([0.0, 0.0])  # Robot\'s current position\r\n        steps = []\r\n        \r\n        # Generate sequence of footsteps\r\n        step_length = self.walk_engine.step_length\r\n        n_steps = int(walk_command[\'distance\'] / step_length) if walk_command.get(\'distance\') else 5\r\n        \r\n        for i in range(n_steps):\r\n            # Alternate feet in a walk pattern\r\n            x = current_pos[0] + step_length * (i + 1)\r\n            y = current_pos[1] + (-1)**i * 0.15  # Alternate left/right\r\n            steps.append(np.array([x, y]))\r\n        \r\n        return steps\r\n    \r\n    def compute_walking_control(self, current_state, walk_command):\r\n        """Compute walking control using MPC"""\r\n        # Plan footsteps\r\n        footsteps = self.plan_footsteps(walk_command)\r\n        \r\n        # Generate reference CoM trajectory to follow footsteps\r\n        ref_trajectory = self.generate_com_reference(footsteps, current_state)\r\n        \r\n        # Get support foot positions for each time step\r\n        support_positions = self.interpolate_support_polygon(footsteps)\r\n        \r\n        # Solve MPC problem\r\n        optimal_control, predicted_trajectory = self.mpc.compute_optimal_control(\r\n            current_state, \r\n            ref_trajectory,\r\n            support_positions\r\n        )\r\n        \r\n        return optimal_control, predicted_trajectory, footsteps\r\n    \r\n    def generate_com_reference(self, footsteps, current_state):\r\n        """Generate CoM reference trajectory based on footsteps"""\r\n        N = self.mpc.N\r\n        dt = self.mpc.dt\r\n        \r\n        # For simplicity, generate a reference that moves between foot positions\r\n        ref_trajectory = np.zeros((N, 4))  # [px, py, vx, vy]\r\n        \r\n        # Initialize with current state\r\n        ref_trajectory[0, :2] = current_state[:2]  # Position\r\n        ref_trajectory[0, 2:] = current_state[2:]  # Velocity\r\n        \r\n        # Generate smooth transition between footstep locations\r\n        if len(footsteps) > 0:\r\n            for k in range(1, N):\r\n                # Move toward the next relevant footstep\r\n                # This is a simplified approach\r\n                target_idx = min(int(k * len(footsteps) / N), len(footsteps) - 1)\r\n                target_pos = footsteps[target_idx][:2]\r\n                \r\n                # Simple first-order tracking\r\n                alpha = 0.1  # Smoothing factor\r\n                ref_trajectory[k, :2] = (1 - alpha) * ref_trajectory[k-1, :2] + alpha * target_pos\r\n                \r\n                # Compute approximate velocity\r\n                if k > 0:\r\n                    ref_trajectory[k, 2:] = (ref_trajectory[k, :2] - ref_trajectory[k-1, :2]) / dt\r\n        \r\n        return ref_trajectory\r\n    \r\n    def interpolate_support_polygon(self, footsteps):\r\n        """Interpolate support polygon positions over the prediction horizon"""\r\n        N = self.mpc.N\r\n        support_positions = []\r\n        \r\n        # For this example, alternate support between feet\r\n        for k in range(N):\r\n            if k < len(footsteps):\r\n                # Use the appropriate foot position based on gait phase\r\n                if k % 2 == 0:\r\n                    # Right foot is stance foot\r\n                    if k + 1 < len(footsteps):\r\n                        support_pos = footsteps[k + 1][:2]\r\n                    else:\r\n                        support_pos = footsteps[k][:2]\r\n                else:\r\n                    # Left foot is stance foot\r\n                    support_pos = footsteps[k][:2]\r\n            else:\r\n                # Use last foot position\r\n                support_pos = footsteps[-1][:2] if footsteps else np.array([0.0, 0.0])\r\n            \r\n            support_positions.append(support_pos)\r\n        \r\n        return support_positions\r\n\r\nclass FootstepPlanner:\r\n    def __init__(self):\r\n        self.step_width = 0.3  # Default distance between feet\r\n        self.max_step_length = 0.5  # Maximum step length\r\n        \r\n    def plan_to_target(self, current_pos, target_pos, terrain_map=None):\r\n        """Plan footsteps from current position to target position"""\r\n        # Calculate required steps\r\n        displacement = target_pos - current_pos\r\n        distance = np.linalg.norm(displacement)\r\n        \r\n        # Calculate number of steps needed\r\n        n_steps = max(1, int(np.ceil(distance / self.max_step_length)))\r\n        \r\n        # Generate evenly spaced steps\r\n        footsteps = []\r\n        for i in range(1, n_steps + 1):\r\n            ratio = i / n_steps\r\n            step_pos = current_pos + ratio * displacement\r\n            \r\n            # Alternate foot placement (left-right-left...)\r\n            if i % 2 == 1:\r\n                # Offset in Y for first foot\r\n                step_pos[1] += self.step_width / 2\r\n            else:\r\n                # Offset in Y for second foot\r\n                step_pos[1] -= self.step_width / 2\r\n                \r\n            footsteps.append(step_pos)\r\n        \r\n        return footsteps\n'})}),"\n",(0,t.jsx)(n.h2,{id:"-114-learning-based-control-",children:"\ud83c\udfaf 11.4 Learning-Based Control \ud83c\udfaf"}),"\n",(0,t.jsx)(n.h3,{id:"-1141-imitation-learning-for-humanoid-movements-",children:"\ud83c\udfaf 11.4.1 Imitation Learning for Humanoid Movements \ud83c\udfaf"}),"\n",(0,t.jsx)(n.p,{children:"Humanoid robots can learn complex movements through imitation of human demonstrations:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport numpy as np\r\n\r\nclass HumanoidImitationLearner(nn.Module):\r\n    def __init__(self, state_dim, action_dim, hidden_dim=256):\r\n        super(HumanoidImitationLearner, self).__init__()\r\n        \r\n        # State encoder\r\n        self.state_encoder = nn.Sequential(\r\n            nn.Linear(state_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, hidden_dim),\r\n            nn.ReLU()\r\n        )\r\n        \r\n        # Action decoder\r\n        self.action_decoder = nn.Sequential(\r\n            nn.Linear(hidden_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, action_dim),\r\n            nn.Tanh()  # Actions are normalized to [-1, 1]\r\n        )\r\n\r\n    def forward(self, state):\r\n        encoded_state = self.state_encoder(state)\r\n        action = self.action_decoder(encoded_state)\r\n        return action\r\n\r\nclass HumanoidImitationController:\r\n    def __init__(self, state_dim, action_dim, learning_rate=1e-4):\r\n        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")\r\n        \r\n        self.learner = HumanoidImitationLearner(state_dim, action_dim).to(self.device)\r\n        self.optimizer = torch.optim.Adam(self.learner.parameters(), lr=learning_rate)\r\n        self.criterion = nn.MSELoss()\r\n        \r\n        # Storage for demonstration data\r\n        self.demonstration_states = []\r\n        self.demonstration_actions = []\r\n        \r\n    def add_demonstration(self, states, actions):\r\n        """Add a demonstration trajectory to the dataset"""\r\n        self.demonstration_states.extend(states)\r\n        self.demonstration_actions.extend(actions)\r\n    \r\n    def train(self, epochs=100, batch_size=64):\r\n        """Train the imitation learning model"""\r\n        if len(self.demonstration_states) == 0:\r\n            print("No demonstrations available for training")\r\n            return\r\n        \r\n        # Convert to tensors\r\n        states_tensor = torch.FloatTensor(self.demonstration_states).to(self.device)\r\n        actions_tensor = torch.FloatTensor(self.demonstration_actions).to(self.device)\r\n        \r\n        dataset = torch.utils.data.TensorDataset(states_tensor, actions_tensor)\r\n        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\r\n        \r\n        self.learner.train()\r\n        for epoch in range(epochs):\r\n            total_loss = 0\r\n            for batch_states, batch_actions in dataloader:\r\n                self.optimizer.zero_grad()\r\n                \r\n                predicted_actions = self.learner(batch_states)\r\n                loss = self.criterion(predicted_actions, batch_actions)\r\n                \r\n                loss.backward()\r\n                self.optimizer.step()\r\n                \r\n                total_loss += loss.item()\r\n            \r\n            if epoch % 20 == 0:\r\n                print(f"Epoch {epoch}, Loss: {total_loss/len(dataloader):.4f}")\r\n    \r\n    def get_action(self, state):\r\n        """Get action for a given state"""\r\n        self.learner.eval()\r\n        with torch.no_grad():\r\n            state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)\r\n            action = self.learner(state_tensor)\r\n            return action.cpu().numpy().squeeze()\r\n\r\n# \u2139\ufe0f Demonstration collection system \u2139\ufe0f\r\nclass DemonstrationCollector:\r\n    def __init__(self, robot_interface, human_motion_capture):\r\n        self.robot = robot_interface\r\n        self.motion_capture = human_motion_capture\r\n        self.current_demonstration = {\'states\': [], \'actions\': []}\r\n        \r\n    def start_demonstration(self):\r\n        """Start collecting a new demonstration"""\r\n        self.current_demonstration = {\'states\': [], \'actions\': []}\r\n        print("Started collecting demonstration")\r\n    \r\n    def record_step(self, robot_state, human_motion_state):\r\n        """Record a single step of the demonstration"""\r\n        # Map human motion to robot actions\r\n        robot_action = self.map_human_to_robot(human_motion_state)\r\n        \r\n        self.current_demonstration[\'states\'].append(robot_state)\r\n        self.current_demonstration[\'actions\'].append(robot_action)\r\n    \r\n    def map_human_to_robot(self, human_pose):\r\n        """Map human motion capture data to robot joint commands"""\r\n        # This would involve complex kinematic mapping\r\n        # taking into account differences in kinematic structure\r\n        # For this example, we\'ll use a simplified mapping\r\n        \r\n        # Assume human pose contains joint angles for a human skeleton\r\n        # and we need to map them to robot joint angles\r\n        n_robot_joints = 30  # Example number of humanoid joints\r\n        \r\n        # Simplified mapping (in practice this would be more sophisticated)\r\n        robot_action = np.zeros(n_robot_joints)\r\n        \r\n        # Map common joints: hips, knees, ankles, shoulders, elbows, wrists\r\n        # This is highly simplified - real implementations would use IK to match poses\r\n        for i in range(min(len(human_pose), n_robot_joints)):\r\n            robot_action[i] = human_pose[i] if i < len(human_pose) else 0.0\r\n        \r\n        return robot_action\r\n    \r\n    def end_demonstration(self):\r\n        """End the current demonstration and return it"""\r\n        demo = self.current_demonstration.copy()\r\n        self.current_demonstration = {\'states\': [], \'actions\': []}\r\n        print(f"Completed demonstration with {len(demo[\'states\'])} steps")\r\n        return demo\n'})}),"\n",(0,t.jsx)(n.h3,{id:"-1142-reinforcement-learning-for-humanoid-control-",children:"\ud83c\udfaf 11.4.2 Reinforcement Learning for Humanoid Control \ud83c\udfaf"}),"\n",(0,t.jsx)(n.p,{children:"Reinforcement learning can be used to learn complex humanoid behaviors:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import torch\r\nimport torch.nn as nn\r\nimport numpy as np\r\nimport random\r\nfrom collections import deque\r\n\r\nclass HumanoidActor(nn.Module):\r\n    def __init__(self, state_dim, action_dim, hidden_dim=256):\r\n        super(HumanoidActor, self).__init__()\r\n        \r\n        self.network = nn.Sequential(\r\n            nn.Linear(state_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, action_dim),\r\n            nn.Tanh()\r\n        )\r\n        \r\n        # Learnable standard deviation for exploration\r\n        self.log_std = nn.Parameter(torch.zeros(action_dim))\r\n\r\n    def forward(self, state):\r\n        action_mean = self.network(state)\r\n        action_std = torch.exp(self.log_std)\r\n        return action_mean, action_std\r\n\r\nclass HumanoidCritic(nn.Module):\r\n    def __init__(self, state_dim, hidden_dim=256):\r\n        super(HumanoidCritic, self).__init__()\r\n        \r\n        self.network = nn.Sequential(\r\n            nn.Linear(state_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Linear(hidden_dim, 1)\r\n        )\r\n\r\n    def forward(self, state):\r\n        return self.network(state)\r\n\r\nclass HumanoidPPOAgent:\r\n    def __init__(self, state_dim, action_dim, lr_actor=3e-4, lr_critic=1e-3, \r\n                 gamma=0.99, clip_epsilon=0.2, epochs=10):\r\n        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")\r\n        \r\n        # Networks\r\n        self.actor = HumanoidActor(state_dim, action_dim).to(self.device)\r\n        self.critic = HumanoidCritic(state_dim).to(self.device)\r\n        \r\n        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=lr_actor)\r\n        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr_critic)\r\n        \r\n        # Hyperparameters\r\n        self.gamma = gamma\r\n        self.clip_epsilon = clip_epsilon\r\n        self.epochs = epochs\r\n        \r\n        # For updating old policy\r\n        self.old_actor = HumanoidActor(state_dim, action_dim).to(self.device)\r\n        self.update_old_policy()\r\n        \r\n    def update_old_policy(self):\r\n        """Update old policy network with current policy parameters"""\r\n        self.old_actor.load_state_dict(self.actor.state_dict())\r\n    \r\n    def select_action(self, state):\r\n        """Select action using current policy"""\r\n        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)\r\n        \r\n        with torch.no_grad():\r\n            action_mean, action_std = self.old_actor(state_tensor)\r\n            \r\n            # Sample action from normal distribution\r\n            action_distribution = torch.distributions.Normal(action_mean, action_std)\r\n            action = action_distribution.sample()\r\n            log_prob = action_distribution.log_prob(action).sum(dim=-1)\r\n        \r\n        return action.cpu().numpy()[0], log_prob.cpu().numpy()[0]\r\n    \r\n    def evaluate(self, state, action):\r\n        """Evaluate state-action pairs"""\r\n        state_tensor = torch.FloatTensor(state).to(self.device)\r\n        action_tensor = torch.FloatTensor(action).to(self.device)\r\n        \r\n        action_mean, action_std = self.actor(state_tensor)\r\n        action_distribution = torch.distributions.Normal(action_mean, action_std)\r\n        log_prob = action_distribution.log_prob(action_tensor).sum(dim=-1, keepdim=True)\r\n        \r\n        entropy = action_distribution.entropy().sum(dim=-1, keepdim=True)\r\n        state_value = self.critic(state_tensor)\r\n        \r\n        return log_prob, entropy, state_value\r\n\r\n    def update(self, states, actions, rewards, dones, log_probs, values):\r\n        """Update policy using PPO"""\r\n        states = torch.FloatTensor(states).to(self.device)\r\n        actions = torch.FloatTensor(actions).to(self.device)\r\n        rewards = torch.FloatTensor(rewards).to(self.device)\r\n        dones = torch.BoolTensor(dones).to(self.device)\r\n        old_log_probs = torch.FloatTensor(log_probs).to(self.device)\r\n        \r\n        # Compute discounted rewards (returns)\r\n        returns = []\r\n        R = 0\r\n        for reward, done in zip(reversed(rewards), reversed(dones)):\r\n            if done:\r\n                R = 0\r\n            R = reward + self.gamma * R\r\n            returns.insert(0, R)\r\n        returns = torch.FloatTensor(returns).to(self.device).unsqueeze(1)\r\n        \r\n        # Advantages\r\n        advantages = returns - values\r\n        \r\n        # Normalize advantages\r\n        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\r\n        \r\n        # Update policy for several epochs\r\n        for _ in range(self.epochs):\r\n            # Get new probabilities and values\r\n            new_log_probs, entropy, new_values = self.evaluate(states, actions)\r\n            \r\n            # Compute ratios\r\n            ratios = torch.exp(new_log_probs - old_log_probs)\r\n            \r\n            # Compute PPO surrogates\r\n            surr1 = ratios * advantages\r\n            surr2 = torch.clamp(ratios, 1 - self.clip_epsilon, 1 + self.clip_epsilon) * advantages\r\n            actor_loss = -torch.min(surr1, surr2).mean()\r\n            \r\n            # Critic loss\r\n            critic_loss = F.mse_loss(new_values, returns)\r\n            \r\n            # Total loss\r\n            total_loss = actor_loss + 0.5 * critic_loss - 0.01 * entropy.mean()\r\n            \r\n            # Update networks\r\n            self.actor_optimizer.zero_grad()\r\n            total_loss.backward()\r\n            self.actor_optimizer.step()\r\n            \r\n            self.critic_optimizer.zero_grad()\r\n            critic_loss.backward()\r\n            self.critic_optimizer.step()\r\n        \r\n        # Update old policy\r\n        self.update_old_policy()\r\n\r\n# \u2139\ufe0f Humanoid Environment for RL \u2139\ufe0f\r\nclass HumanoidEnvironment:\r\n    def __init__(self, robot_model):\r\n        self.robot = robot_model\r\n        self.action_space_dim = robot_model.n_joints\r\n        self.observation_space_dim = 100  # Simplified state space\r\n        \r\n        # Episode tracking\r\n        self.step_count = 0\r\n        self.max_steps = 1000\r\n        \r\n        # Reward components\r\n        self.reward_weights = {\r\n            \'forward_progress\': 1.0,\r\n            \'balance\': 2.0,\r\n            \'energy_efficiency\': 0.1,\r\n            \'upright\': 1.5\r\n        }\r\n    \r\n    def reset(self):\r\n        """Reset the environment"""\r\n        self.step_count = 0\r\n        \r\n        # Reset robot to standing position\r\n        initial_state = self.robot.get_initial_state()\r\n        \r\n        return initial_state\r\n    \r\n    def step(self, action):\r\n        """Take a step in the environment"""\r\n        self.step_count += 1\r\n        \r\n        # Apply action to robot\r\n        self.robot.apply_action(action)\r\n        \r\n        # Get new state\r\n        new_state = self.robot.get_state()\r\n        \r\n        # Calculate reward\r\n        reward = self.calculate_reward(new_state, action)\r\n        \r\n        # Check if episode is done\r\n        done = (self.step_count >= self.max_steps or \r\n                self.check_fall_condition(new_state))\r\n        \r\n        # Additional info (for debugging)\r\n        info = {\r\n            \'step\': self.step_count,\r\n            \'com_height\': new_state[2],  # Simplified\r\n            \'is_fallen\': self.check_fall_condition(new_state)\r\n        }\r\n        \r\n        return new_state, reward, done, info\r\n    \r\n    def calculate_reward(self, state, action):\r\n        """Calculate reward based on state and action"""\r\n        reward = 0.0\r\n        \r\n        # Forward progress reward (simplified)\r\n        com_velocity_x = state[3]  # Simplified - assume 4th element is CoM velocity X\r\n        reward += self.reward_weights[\'forward_progress\'] * max(0, com_velocity_x)\r\n        \r\n        # Balance reward - penalize deviation from upright position\r\n        robot_orientation = state[6:9]  # Simplified - assume orientation is elements 6-8\r\n        upright_penalty = np.sum(robot_orientation[0:2]**2)  # Penalize roll and pitch\r\n        reward -= self.reward_weights[\'balance\'] * upright_penalty\r\n        \r\n        # Energy efficiency - penalize large actions\r\n        action_penalty = np.sum(action**2)\r\n        reward -= self.reward_weights[\'energy_efficiency\'] * action_penalty\r\n        \r\n        # Upright bonus - reward for maintaining upright position\r\n        if abs(state[2] - 0.8) < 0.1:  # If CoM height is close to nominal\r\n            reward += self.reward_weights[\'upright\']\r\n        \r\n        return reward\r\n    \r\n    def check_fall_condition(self, state):\r\n        """Check if robot has fallen"""\r\n        # Simplified fall detection - check if CoM is too low or tilted too much\r\n        com_height = state[2]  # Simplified assumption\r\n        orientation = state[6:9]  # Simplified assumption\r\n        \r\n        # Fall if CoM is too low or tilted beyond threshold\r\n        fallen = (com_height < 0.3 or \r\n                 abs(orientation[0]) > 0.5 or  # Roll\r\n                 abs(orientation[1]) > 0.5)    # Pitch\r\n        \r\n        return fallen\r\n\r\n# \ud83e\udd16 Training loop for humanoid RL \ud83e\udd16\r\ndef train_humanoid_rl_agent():\r\n    """Training loop for humanoid reinforcement learning"""\r\n    # Initialize environment and agent\r\n    robot_model = SimpleHumanoidModel()  # Placeholder\r\n    env = HumanoidEnvironment(robot_model)\r\n    \r\n    agent = HumanoidPPOAgent(\r\n        state_dim=env.observation_space_dim,\r\n        action_dim=env.action_space_dim,\r\n        lr_actor=3e-4,\r\n        lr_critic=1e-3\r\n    )\r\n    \r\n    # Training parameters\r\n    max_episodes = 1000\r\n    update_timestep = 2000  # Update policy every N timesteps\r\n    \r\n    # Storage for trajectories\r\n    states = []\r\n    actions = []\r\n    log_probs = []\r\n    rewards = []\r\n    is_terminals = []\r\n    \r\n    # Track performance\r\n    running_reward = 0\r\n    avg_length = 0\r\n    \r\n    timestep = 0\r\n    \r\n    for episode in range(max_episodes):\r\n        state = env.reset()\r\n        episode_reward = 0\r\n        time_steps = 0\r\n        \r\n        for _ in range(update_timestep):\r\n            timestep += 1\r\n            time_steps += 1\r\n            \r\n            # Select action\r\n            action, log_prob = agent.select_action(state)\r\n            \r\n            # Take action in environment\r\n            new_state, reward, done, info = env.step(action)\r\n            \r\n            # Store data\r\n            states.append(state)\r\n            actions.append(action)\r\n            log_probs.append(log_prob)\r\n            rewards.append(reward)\r\n            is_terminals.append(done)\r\n            \r\n            state = new_state\r\n            episode_reward += reward\r\n            \r\n            if done:\r\n                break\r\n        \r\n        # Update running reward\r\n        running_reward += episode_reward\r\n        avg_length += time_steps\r\n        \r\n        # Update policy if enough samples collected\r\n        if timestep % update_timestep == 0:\r\n            # Convert to numpy arrays for PPO update\r\n            np_states = torch.FloatTensor(states).detach().numpy()\r\n            np_actions = torch.FloatTensor(actions).detach().numpy()\r\n            np_rewards = torch.FloatTensor(rewards).detach().numpy()\r\n            np_is_terminals = torch.BoolTensor(is_terminals).detach().numpy()\r\n            \r\n            # Get old values for PPO update\r\n            with torch.no_grad():\r\n                old_values = agent.critic(torch.FloatTensor(states)).detach().numpy()\r\n            \r\n            # Update agent\r\n            agent.update(np_states, np_actions, np_rewards, np_is_terminals, log_probs, old_values)\r\n            \r\n            # Clear storage\r\n            states = []\r\n            actions = []\r\n            log_probs = []\r\n            rewards = []\r\n            is_terminals = []\r\n        \r\n        # Print average reward every 10 episodes\r\n        if episode % 10 == 0:\r\n            avg_reward = running_reward / 10\r\n            avg_length = int(avg_length / 10)\r\n            print(f\'Episode {episode}, avg length: {avg_length}, reward: {avg_reward:.2f}\')\r\n            running_reward = 0\r\n            avg_length = 0\r\n\r\n# \ud83e\udd16 Placeholder for simple humanoid model (would be implemented with real robot/physics) \ud83e\udd16\r\nclass SimpleHumanoidModel:\r\n    def __init__(self):\r\n        self.n_joints = 30  # Example humanoid joint count\r\n        self.mass = 75  # kg\r\n        self.height = 1.8  # meters\r\n    \r\n    def get_initial_state(self):\r\n        """Get initial state of the robot"""\r\n        # Return a 100-dimensional state vector (simplified)\r\n        return np.zeros(100)\r\n    \r\n    def get_state(self):\r\n        """Get current state of the robot"""\r\n        # Return current state (simplified)\r\n        return np.random.randn(100)\r\n    \r\n    def apply_action(self, action):\r\n        """Apply action to the robot"""\r\n        # In real implementation, send commands to robot\r\n        pass\n'})}),"\n",(0,t.jsx)(n.h2,{id:"\ufe0f-115-control-validation-and-testing-\ufe0f",children:"\ud83c\udf9b\ufe0f 11.5 Control Validation and Testing \ud83c\udf9b\ufe0f"}),"\n",(0,t.jsx)(n.h3,{id:"-1151-simulation-based-validation-",children:"\ud83c\udfae 11.5.1 Simulation-Based Validation \ud83c\udfae"}),"\n",(0,t.jsx)(n.p,{children:"Validating humanoid control systems in simulation before real-world deployment:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom scipy.spatial.transform import Rotation as R\r\n\r\nclass HumanoidSimulator:\r\n    def __init__(self, physics_engine='pybullet'):\r\n        self.engine = physics_engine\r\n        self.timestep = 0.001  # 1kHz simulation\r\n        self.robot_id = None\r\n        \r\n        # Robot properties\r\n        self.mass = 75.0  # kg\r\n        self.height = 1.7  # meters\r\n        self.base_position = [0, 0, 0.8]  # Standing position\r\n        \r\n        # Simulation state\r\n        self.sim_step = 0\r\n        self.contact_points = []\r\n        \r\n    def reset(self):\r\n        \"\"\"Reset simulation to initial state\"\"\"\r\n        self.sim_step = 0\r\n        self.contact_points = []\r\n        \r\n        # Initialize robot at standing position\r\n        # Implementation would depend on physics engine\r\n        pass\r\n    \r\n    def step(self, joint_commands):\r\n        \"\"\"Step simulation with joint commands\"\"\"\r\n        # Apply joint commands to robot\r\n        # Update physics simulation\r\n        # Check for contacts, collisions, etc.\r\n        \r\n        self.sim_step += 1\r\n        \r\n        # Return updated robot state\r\n        # This would include joint positions, velocities, IMU data, etc.\r\n        return self.get_robot_state()\r\n    \r\n    def get_robot_state(self):\r\n        \"\"\"Get current robot state\"\"\"\r\n        # Return comprehensive robot state for controller\r\n        state = {\r\n            'joint_positions': np.random.randn(30),  # Placeholder\r\n            'joint_velocities': np.random.randn(30),  # Placeholder\r\n            'imu_data': {\r\n                'orientation': np.random.randn(4),  # Quaternion\r\n                'angular_velocity': np.random.randn(3),\r\n                'linear_acceleration': np.random.randn(3)\r\n            },\r\n            'ft_sensors': np.random.randn(6),  # 6-axis force/torque (placeholder)\r\n            'com_state': np.random.randn(6),  # Position and velocity of CoM\r\n            'contact_states': self.get_contact_states()\r\n        }\r\n        return state\r\n    \r\n    def get_contact_states(self):\r\n        \"\"\"Get current contact states\"\"\"\r\n        # Return information about which parts of the robot are in contact\r\n        return {\r\n            'left_foot': np.random.random() > 0.5,  # Whether in contact\r\n            'right_foot': np.random.random() > 0.5,\r\n            'contact_forces': np.random.randn(2, 6)  # Forces at each foot\r\n        }\r\n    \r\n    def add_disturbance(self, force, position, duration=100):\r\n        \"\"\"Add an external disturbance to the robot\"\"\"\r\n        # Apply external force for specified duration\r\n        # This is useful for testing robustness\r\n        pass\r\n\r\nclass ControlValidator:\r\n    def __init__(self, simulator):\r\n        self.simulator = simulator\r\n        self.test_results = {}\r\n        \r\n    def run_stability_test(self, controller, test_duration=10.0):\r\n        \"\"\"Test controller stability over time\"\"\"\r\n        self.simulator.reset()\r\n        \r\n        initial_state = self.simulator.get_robot_state()\r\n        states = []\r\n        commands = []\r\n        \r\n        n_steps = int(test_duration / self.simulator.timestep)\r\n        \r\n        for i in range(n_steps):\r\n            current_state = self.simulator.get_robot_state()\r\n            states.append(current_state)\r\n            \r\n            # Get control command\r\n            command = controller.compute_command(current_state)\r\n            commands.append(command)\r\n            \r\n            # Step simulation\r\n            next_state = self.simulator.step(command)\r\n            \r\n            # Check for failure conditions\r\n            if self.check_failure_conditions(next_state):\r\n                print(f\"Stability test failed at step {i}\")\r\n                break\r\n        \r\n        # Analyze results\r\n        stability_metrics = self.analyze_stability(states, commands)\r\n        \r\n        self.test_results['stability'] = stability_metrics\r\n        return stability_metrics\r\n    \r\n    def run_robustness_test(self, controller, disturbances=None):\r\n        \"\"\"Test controller robustness to disturbances\"\"\"\r\n        if disturbances is None:\r\n            disturbances = [\r\n                {'force': [50, 0, 0], 'position': [0, 0, 0.5], 'duration': 100},\r\n                {'force': [0, -30, 0], 'position': [0.2, 0, 0.5], 'duration': 100},\r\n                {'force': [0, 0, -100], 'position': [0, 0, 0.7], 'duration': 50}\r\n            ]\r\n        \r\n        self.simulator.reset()\r\n        initial_state = self.simulator.get_robot_state()\r\n        \r\n        for i, dist in enumerate(disturbances):\r\n            print(f\"Applying disturbance {i+1}: {dist['force']}\")\r\n            \r\n            # Apply disturbance\r\n            self.simulator.add_disturbance(\r\n                dist['force'], \r\n                dist['position'], \r\n                dist['duration']\r\n            )\r\n            \r\n            # Run controller for a while after disturbance\r\n            for j in range(500):  # 0.5 seconds at 1kHz\r\n                current_state = self.simulator.get_robot_state()\r\n                command = controller.compute_command(current_state)\r\n                self.simulator.step(command)\r\n                \r\n                # Check recovery\r\n                if self.check_recovery(current_state, initial_state):\r\n                    print(f\"Recovered from disturbance {i+1} at step {j}\")\r\n                    break\r\n        \r\n        # Analyze robustness metrics\r\n        robustness_metrics = self.analyze_robustness()\r\n        self.test_results['robustness'] = robustness_metrics\r\n        return robustness_metrics\r\n    \r\n    def check_failure_conditions(self, state):\r\n        \"\"\"Check if robot has failed (fallen, etc.)\"\"\"\r\n        com_height = state['com_state'][2]  # Z component of CoM\r\n        robot_orientation = state['imu_data']['orientation']\r\n        \r\n        # Convert quaternion to roll/pitch angles\r\n        r = R.from_quat(robot_orientation)\r\n        euler = r.as_euler('xyz')\r\n        \r\n        # Fail if fallen (CoM too low or too tilted)\r\n        fallen = (com_height < 0.3 or \r\n                 abs(euler[0]) > 0.5 or  # Roll\r\n                 abs(euler[1]) > 0.5)    # Pitch\r\n        \r\n        return fallen\r\n    \r\n    def check_recovery(self, current_state, initial_state, tolerance=0.1):\r\n        \"\"\"Check if robot has recovered to stable state\"\"\"\r\n        # Check if CoM position is close to initial\r\n        com_diff = np.linalg.norm(\r\n            current_state['com_state'][:2] - initial_state['com_state'][:2]\r\n        )\r\n        \r\n        return com_diff < tolerance\r\n    \r\n    def analyze_stability(self, states, commands):\r\n        \"\"\"Analyze stability metrics\"\"\"\r\n        # Calculate CoM stability metrics\r\n        com_positions = np.array([s['com_state'][:2] for s in states])\r\n        \r\n        # Mean deviation from center\r\n        mean_deviation = np.mean(np.linalg.norm(com_positions, axis=1))\r\n        \r\n        # Variance of CoM position\r\n        com_variance = np.var(np.linalg.norm(com_positions, axis=1))\r\n        \r\n        # Calculate joint command smoothness\r\n        commands = np.array(commands)\r\n        command_derivatives = np.diff(commands, axis=0)\r\n        command_smoothness = np.mean(np.abs(command_derivatives))\r\n        \r\n        return {\r\n            'mean_com_deviation': mean_deviation,\r\n            'com_variance': com_variance,\r\n            'command_smoothness': command_smoothness,\r\n            'max_com_drift': np.max(np.linalg.norm(com_positions, axis=1))\r\n        }\r\n    \r\n    def analyze_robustness(self):\r\n        \"\"\"Analyze robustness metrics\"\"\"\r\n        # This would analyze how well the controller handled disturbances\r\n        # and recovered to stable behavior\r\n        return {\r\n            'recovery_time_avg': 0.5,  # Placeholder\r\n            'max_disturbance_response': 0.2,  # Placeholder\r\n            'stability_after_disturbance': True  # Placeholder\r\n        }\r\n    \r\n    def visualize_test_results(self):\r\n        \"\"\"Visualize control validation results\"\"\"\r\n        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\r\n        \r\n        if 'stability' in self.test_results:\r\n            stability = self.test_results['stability']\r\n            \r\n            # Plot CoM stability over time (simplified)\r\n            # In practice, you'd have time series data\r\n            time = np.linspace(0, 10, 1000)\r\n            com_x = np.random.randn(1000) * stability['mean_com_deviation'] / 2\r\n            com_y = np.random.randn(1000) * stability['mean_com_deviation'] / 2\r\n            \r\n            axes[0, 0].plot(com_x, com_y)\r\n            axes[0, 0].set_title('Center of Mass Trajectory')\r\n            axes[0, 0].set_xlabel('X Position (m)')\r\n            axes[0, 0].set_ylabel('Y Position (m)')\r\n            axes[0, 0].grid(True)\r\n            \r\n            # Plot command smoothness\r\n            axes[0, 1].plot(time, np.convolve(np.abs(com_x), np.ones(50)/50, mode='same'))\r\n            axes[0, 1].set_title('Smoothed CoM Position X')\r\n            axes[0, 1].set_xlabel('Time (s)')\r\n            axes[0, 1].set_ylabel('Position (m)')\r\n            \r\n        if 'robustness' in self.test_results:\r\n            # Robustness metrics plot\r\n            metrics = list(self.test_results['robustness'].keys())\r\n            values = list(self.test_results['robustness'].values())\r\n            \r\n            axes[1, 0].bar(metrics, values)\r\n            axes[1, 0].set_title('Robustness Metrics')\r\n            axes[1, 0].set_ylabel('Value')\r\n            plt.setp(axes[1, 0].get_xticklabels(), rotation=45)\r\n        \r\n        # Balance margin visualization\r\n        # Create a support polygon and show CoM position\r\n        foot_positions = np.array([\r\n            [0.1, 0.15],   # Left foot\r\n            [0.1, -0.15],  # Right foot\r\n            [-0.1, -0.15], # Right foot (back)\r\n            [-0.1, 0.15]   # Left foot (back)\r\n        ])\r\n        \r\n        axes[1, 1].fill(foot_positions[:, 0], foot_positions[:, 1], alpha=0.3, label='Support Polygon')\r\n        axes[1, 1].plot(0, 0, 'ro', label='CoM (stable)')\r\n        axes[1, 1].plot(0.15, 0.2, 'rx', markersize=10, label='CoM (unstable)')\r\n        axes[1, 1].set_title('Balance Margin Visualization')\r\n        axes[1, 1].set_xlabel('X Position (m)')\r\n        axes[1, 1].set_ylabel('Y Position (m)')\r\n        axes[1, 1].legend()\r\n        axes[1, 1].grid(True)\r\n        \r\n        plt.tight_layout()\r\n        plt.show()\r\n\r\n# \u2139\ufe0f Example usage of validation framework \u2139\ufe0f\r\ndef run_control_validation():\r\n    \"\"\"Run comprehensive control system validation\"\"\"\r\n    print(\"Starting humanoid control validation...\")\r\n    \r\n    # Initialize simulator\r\n    simulator = HumanoidSimulator()\r\n    \r\n    # Create validator\r\n    validator = ControlValidator(simulator)\r\n    \r\n    # For this example, we'll create a simple controller\r\n    # In practice, this would be your actual controller\r\n    class DummyController:\r\n        def compute_command(self, state):\r\n            # Return random commands for this example\r\n            return np.random.randn(30)\r\n    \r\n    controller = DummyController()\r\n    \r\n    # Run stability test\r\n    print(\"Running stability test...\")\r\n    stability_results = validator.run_stability_test(controller, test_duration=5.0)\r\n    print(f\"Stability metrics: {stability_results}\")\r\n    \r\n    # Run robustness test\r\n    print(\"Running robustness test...\")\r\n    robustness_results = validator.run_robustness_test(controller)\r\n    print(f\"Robustness metrics: {robustness_results}\")\r\n    \r\n    # Visualize results\r\n    print(\"Visualizing results...\")\r\n    validator.visualize_test_results()\r\n    \r\n    print(\"Control validation completed.\")\n"})}),"\n",(0,t.jsx)(n.h2,{id:"-116-safety-and-failsafe-systems-",children:"\ud83e\udd16 11.6 Safety and Failsafe Systems \ud83e\udd16"}),"\n",(0,t.jsx)(n.h3,{id:"\ufe0f-1161-emergency-response-systems-\ufe0f",children:"\u2699\ufe0f 11.6.1 Emergency Response Systems \u2699\ufe0f"}),"\n",(0,t.jsx)(n.p,{children:"Critical safety systems for humanoid robots:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import time\r\nimport threading\r\nfrom enum import Enum\r\n\r\nclass SafetyState(Enum):\r\n    NORMAL = "normal"\r\n    WARNING = "warning"\r\n    EMERGENCY = "emergency"\r\n    SHUTDOWN = "shutdown"\r\n\r\nclass EmergencyResponseSystem:\r\n    def __init__(self, robot_controller):\r\n        self.controller = robot_controller\r\n        self.state = SafetyState.NORMAL\r\n        self.emergency_threads = []\r\n        \r\n        # Safety thresholds\r\n        self.safety_thresholds = {\r\n            \'joint_temp\': 80.0,      # Celsius\r\n            \'current\': 20.0,         # Amps\r\n            \'torque\': 100.0,         # Nm\r\n            \'velocity\': 5.0,         # rad/s\r\n            \'acceleration\': 50.0,    # rad/s\xb2\r\n            \'imu_angle\': 0.5,        # Radians (about 28 degrees)\r\n            \'com_drift\': 1.0,        # Meters from nominal\r\n            \'contact_force\': 500.0    # Newtons\r\n        }\r\n        \r\n        # Emergency responses\r\n        self.emergency_responses = {\r\n            \'overheat\': self._handle_overheat,\r\n            \'excessive_current\': self._handle_excessive_current,\r\n            \'fall_detected\': self._handle_fall,\r\n            \'high_torque\': self._handle_high_torque,\r\n            \'imu_violation\': self._handle_imu_violation\r\n        }\r\n        \r\n    def start_monitoring(self):\r\n        """Start safety monitoring in background threads"""\r\n        # Start joint monitoring thread\r\n        joint_monitor = threading.Thread(target=self._joint_monitor_loop)\r\n        joint_monitor.daemon = True\r\n        joint_monitor.start()\r\n        self.emergency_threads.append(joint_monitor)\r\n        \r\n        # Start IMU monitoring thread\r\n        imu_monitor = threading.Thread(target=self._imu_monitor_loop)\r\n        imu_monitor.daemon = True\r\n        imu_monitor.start()\r\n        self.emergency_threads.append(imu_monitor)\r\n        \r\n        # Start contact force monitoring thread\r\n        force_monitor = threading.Thread(target=self._force_monitor_loop)\r\n        force_monitor.daemon = True\r\n        force_monitor.start()\r\n        self.emergency_threads.append(force_monitor)\r\n        \r\n        print("Emergency response system activated")\r\n    \r\n    def _joint_monitor_loop(self):\r\n        """Monitor joint safety parameters"""\r\n        while True:\r\n            if self.state == SafetyState.SHUTDOWN:\r\n                break\r\n                \r\n            # Get current joint states\r\n            joint_states = self.controller.get_joint_states()\r\n            \r\n            for i, joint_state in enumerate(joint_states):\r\n                # Check temperature\r\n                if joint_state[\'temperature\'] > self.safety_thresholds[\'joint_temp\']:\r\n                    self.trigger_emergency(\'overheat\', f\'Joint {i} temperature too high\')\r\n                \r\n                # Check current\r\n                if abs(joint_state[\'current\']) > self.safety_thresholds[\'current\']:\r\n                    self.trigger_emergency(\'excessive_current\', f\'Joint {i} current too high\')\r\n                \r\n                # Check torque\r\n                if abs(joint_state[\'torque\']) > self.safety_thresholds[\'torque\']:\r\n                    self.trigger_emergency(\'high_torque\', f\'Joint {i} torque too high\')\r\n                \r\n                # Check velocity\r\n                if abs(joint_state[\'velocity\']) > self.safety_thresholds[\'velocity\']:\r\n                    self.trigger_emergency(\'high_velocity\', f\'Joint {i} velocity too high\')\r\n            \r\n            time.sleep(0.01)  # Check every 10ms\r\n    \r\n    def _imu_monitor_loop(self):\r\n        """Monitor IMU data for safety violations"""\r\n        while True:\r\n            if self.state == SafetyState.SHUTDOWN:\r\n                break\r\n                \r\n            # Get IMU data\r\n            imu_data = self.controller.get_imu_data()\r\n            \r\n            # Check orientation\r\n            orientation = imu_data[\'orientation\']\r\n            if max(abs(orientation[:3])) > self.safety_thresholds[\'imu_angle\']:\r\n                self.trigger_emergency(\'imu_violation\', f\'Excessive tilt detected: {orientation[:3]}\')\r\n            \r\n            # Check acceleration\r\n            linear_acc = imu_data[\'linear_acceleration\']\r\n            if np.linalg.norm(linear_acc) > 50.0:  # Very high acceleration indicates impact\r\n                self.trigger_emergency(\'imu_violation\', f\'High acceleration detected: {linear_acc}\')\r\n            \r\n            time.sleep(0.01)\r\n    \r\n    def _force_monitor_loop(self):\r\n        """Monitor contact forces"""\r\n        while True:\r\n            if self.state == SafetyState.SHUTDOWN:\r\n                break\r\n                \r\n            # Get force/torque sensor data\r\n            ft_data = self.controller.get_force_torque_data()\r\n            \r\n            # Check for excessive forces\r\n            for i, force_read in enumerate(ft_data):\r\n                if np.linalg.norm(force_read[:3]) > self.safety_thresholds[\'contact_force\']:\r\n                    self.trigger_emergency(\'high_force\', f\'High contact force on sensor {i}\')\r\n            \r\n            time.sleep(0.01)\r\n    \r\n    def trigger_emergency(self, emergency_type, description):\r\n        """Trigger emergency response"""\r\n        print(f"EMERGENCY TRIGGERED: {emergency_type} - {description}")\r\n        \r\n        # Update safety state\r\n        self.state = SafetyState.EMERGENCY\r\n        \r\n        # Execute emergency response\r\n        if emergency_type in self.emergency_responses:\r\n            self.emergency_responses[emergency_type]()\r\n        \r\n        # Log the emergency\r\n        self._log_emergency(emergency_type, description)\r\n    \r\n    def _handle_overheat(self):\r\n        """Handle overheat emergency"""\r\n        print("Handling overheat emergency...")\r\n        # Reduce power to joints\r\n        # Activate cooling systems if available\r\n        # Slow down movements\r\n        self.controller.reduce_power(0.5)\r\n    \r\n    def _handle_excessive_current(self):\r\n        """Handle excessive current emergency"""\r\n        print("Handling excessive current emergency...")\r\n        # Reduce torque commands\r\n        # Check for mechanical obstructions\r\n        self.controller.safety_stop()\r\n    \r\n    def _handle_fall(self):\r\n        """Handle fall detection"""\r\n        print("Handling fall emergency...")\r\n        # Execute fall protection sequence\r\n        # Minimize impact\r\n        # Prepare for recovery\r\n        self.controller.execute_fall_protection()\r\n    \r\n    def _handle_high_torque(self):\r\n        """Handle high torque emergency"""\r\n        print("Handling high torque emergency...")\r\n        # Reduce torque commands\r\n        # Check for collisions\r\n        self.controller.safety_stop()\r\n    \r\n    def _handle_imu_violation(self):\r\n        """Handle IMU safety violation"""\r\n        print("Handling IMU violation emergency...")\r\n        # Stop dynamic movements\r\n        # Return to stable pose if possible\r\n        self.controller.return_to_safe_pose()\r\n    \r\n    def _log_emergency(self, emergency_type, description):\r\n        """Log emergency to safety system"""\r\n        timestamp = time.time()\r\n        log_entry = {\r\n            \'timestamp\': timestamp,\r\n            \'type\': emergency_type,\r\n            \'description\': description,\r\n            \'state\': self.state.value,\r\n            \'controller_state\': self.controller.get_state()\r\n        }\r\n        \r\n        # In practice, this would write to a safety log file\r\n        print(f"Logged emergency: {log_entry}")\r\n    \r\n    def shutdown_safely(self):\r\n        """Shut down the robot safely"""\r\n        print("Initiating safe shutdown...")\r\n        \r\n        # Update state\r\n        self.state = SafetyState.SHUTDOWN\r\n        \r\n        # Stop all movements\r\n        self.controller.emergency_stop()\r\n        \r\n        # Power down systems safely\r\n        self.controller.power_down()\r\n        \r\n        print("Robot safely shut down")\r\n\r\n# \u2139\ufe0f Fall Protection System \u2139\ufe0f\r\nclass FallProtectionSystem:\r\n    def __init__(self, robot_controller):\r\n        self.controller = robot_controller\r\n        self.fall_threshold = 0.3  # Threshold for fall detection (CoM height)\r\n        self.arm_positions = np.zeros(10)  # Positions for protective arm movements\r\n        \r\n    def detect_fall(self, sensor_data):\r\n        """Detect if a fall is occurring"""\r\n        # Check if CoM height is dropping rapidly\r\n        com_height = sensor_data.get(\'com_height\', 0.8)\r\n        com_velocity_z = sensor_data.get(\'com_velocity\', [0, 0, 0])[2]\r\n        \r\n        # Check if falling (negative z velocity and low height)\r\n        is_falling = (com_velocity_z < -0.5 and com_height < self.fall_threshold)\r\n        \r\n        # Also check orientation\r\n        orientation = sensor_data.get(\'orientation\', [0, 0, 0, 1])\r\n        roll_pitch = np.abs(orientation[:2])\r\n        high_tilt = np.any(roll_pitch > 0.6)  # About 34 degrees\r\n        \r\n        return is_falling or high_tilt\r\n    \r\n    def execute_protection_sequence(self):\r\n        """Execute fall protection sequence"""\r\n        print("Executing fall protection...")\r\n        \r\n        # Move arms to protective positions\r\n        self.controller.move_arms_to_protection()\r\n        \r\n        # If possible, try to break fall with legs\r\n        self.controller.prepare_legs_for_impact()\r\n        \r\n        # Reduce stiffness to minimize damage\r\n        self.controller.reduce_impedance()\r\n        \r\n        # Activate shock absorption if available\r\n        self.controller.activate_shock_absorption()\r\n\r\n# \u2139\ufe0f Safe Recovery System \u2139\ufe0f\r\nclass SafeRecoverySystem:\r\n    def __init__(self, robot_controller):\r\n        self.controller = robot_controller\r\n        self.recovery_poses = self._define_recovery_poses()\r\n        \r\n    def _define_recovery_poses(self):\r\n        """Define safe recovery poses"""\r\n        return {\r\n            \'kneel\': np.array([0, 0, -0.5, 0, 0, 0] * 2 + [0] * 18),  # Kneeling position\r\n            \'crawl\': np.array([0.2, 0, -0.3, -0.2, 0, 0.3] * 2 + [0] * 18),  # Crawling position\r\n            \'crawl_forward\': np.array([0.3, 0.1, -0.2, -0.3, -0.1, 0.2] * 2 + [0] * 18)  # Moving forward on knees\r\n        }\r\n    \r\n    def attempt_recovery(self, from_pose=\'fallen\'):\r\n        """Attempt to recover from fallen state"""\r\n        if from_pose == \'fallen\':\r\n            # First, move to a stable intermediate pose\r\n            success = self.controller.move_to_pose(self.recovery_poses[\'kneel\'], duration=3.0)\r\n            \r\n            if success:\r\n                # Then attempt to stand up\r\n                return self._attempt_standup()\r\n            else:\r\n                print("Could not move to kneeling position, requesting assistance")\r\n                return False\r\n        \r\n        return False\r\n    \r\n    def _attempt_standup(self):\r\n        """Attempt to stand up from kneeling position"""\r\n        print("Attempting to stand up...")\r\n        \r\n        # Gradual standup motion\r\n        standup_trajectory = self._generate_standup_trajectory()\r\n        \r\n        # Execute standup\r\n        success = self.controller.execute_trajectory(standup_trajectory, duration=5.0)\r\n        \r\n        if success:\r\n            print("Successfully stood up")\r\n            # Verify balance\r\n            if self._verify_balance():\r\n                print("Balance verified after standup")\r\n                return True\r\n            else:\r\n                print("Failed to achieve stable balance after standup")\r\n                return False\r\n        else:\r\n            print("Standup motion failed")\r\n            return False\r\n    \r\n    def _generate_standup_trajectory(self):\r\n        """Generate standup motion trajectory"""\r\n        # This would generate a smooth trajectory from kneeling to standing\r\n        # Simplified for this example\r\n        n_points = 50\r\n        trajectory = []\r\n        \r\n        # Interpolate from kneeling to standing\r\n        kneeling_pos = self.recovery_poses[\'kneel\']\r\n        standing_pos = np.zeros(30)  # Default standing position\r\n        \r\n        for i in range(n_points):\r\n            ratio = i / (n_points - 1)\r\n            pos = kneeling_pos * (1 - ratio) + standing_pos * ratio\r\n            trajectory.append(pos)\r\n        \r\n        return trajectory\r\n    \r\n    def _verify_balance(self):\r\n        """Verify that robot is in stable balance after recovery"""\r\n        # Check that CoM is within support polygon\r\n        # Check that robot is upright\r\n        # Check that no joints are in unsafe configurations\r\n        \r\n        state = self.controller.get_state()\r\n        com_height = state.get(\'com_height\', 0.8)\r\n        orientation = state.get(\'orientation\', [0, 0, 0, 1])\r\n        \r\n        # Check if upright\r\n        is_upright = abs(orientation[0]) < 0.1 and abs(orientation[1]) < 0.1  # Small roll/pitch\r\n        is_at_correct_height = 0.7 < com_height < 0.9  # Within reasonable range for standing\r\n        \r\n        return is_upright and is_at_correct_height\n'})}),"\n",(0,t.jsx)(n.h3,{id:"-1162-compliance-and-safety-standards-",children:"\ud83d\udccf 11.6.2 Compliance and Safety Standards \ud83d\udccf"}),"\n",(0,t.jsx)(n.p,{children:"Understanding and implementing safety standards for humanoid robots:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"class SafetyComplianceSystem:\r\n    def __init__(self):\r\n        self.safety_standards = {\r\n            'ISO 13482': {\r\n                'description': 'Safety requirements for personal care robots',\r\n                'requirements': [\r\n                    'Risk assessment and mitigation',\r\n                    'Emergency stop functionality',\r\n                    'Safe interaction with humans',\r\n                    'System reliability'\r\n                ]\r\n            },\r\n            'ISO 12100': {\r\n                'description': 'Safety of machinery - General principles',\r\n                'requirements': [\r\n                    'Risk analysis',\r\n                    'Safety functions',\r\n                    'Verification and validation'\r\n                ]\r\n            }\r\n        }\r\n        \r\n        self.compliance_status = {}\r\n        \r\n    def verify_compliance(self, robot_system):\r\n        \"\"\"Verify compliance with safety standards\"\"\"\r\n        results = {}\r\n        \r\n        for standard, requirements in self.safety_standards.items():\r\n            standard_result = {\r\n                'compliant': True,\r\n                'violations': [],\r\n                'recommendations': []\r\n            }\r\n            \r\n            # Check each requirement\r\n            for req in requirements['requirements']:\r\n                if not self._check_requirement(robot_system, req):\r\n                    standard_result['compliant'] = False\r\n                    standard_result['violations'].append(req)\r\n                    standard_result['recommendations'].append(\r\n                        self._get_recommendation_for_requirement(req)\r\n                    )\r\n            \r\n            results[standard] = standard_result\r\n        \r\n        self.compliance_status = results\r\n        return results\r\n    \r\n    def _check_requirement(self, robot_system, requirement):\r\n        \"\"\"Check if a specific requirement is met\"\"\"\r\n        # Implementation would check specific requirements\r\n        # For this example, we'll implement a few common checks\r\n        \r\n        if 'emergency stop' in requirement.lower():\r\n            # Check if emergency stop is properly implemented\r\n            return robot_system.has_emergency_stop()\r\n        \r\n        elif 'risk assessment' in requirement.lower():\r\n            # Check if risk assessment has been documented\r\n            return robot_system.has_risk_assessment()\r\n        \r\n        elif 'safe interaction' in requirement.lower():\r\n            # Check if safe interaction protocols are implemented\r\n            return robot_system.has_safe_interaction_protocols()\r\n        \r\n        else:\r\n            # Default to compliant for this example\r\n            return True\r\n    \r\n    def _get_recommendation_for_requirement(self, requirement):\r\n        \"\"\"Get recommendation for addressing a requirement\"\"\"\r\n        recommendations = {\r\n            'emergency stop functionality': 'Implement emergency stop button accessible to operator',\r\n            'risk assessment and mitigation': 'Conduct formal risk assessment and document mitigation strategies',\r\n            'safe interaction with humans': 'Implement collision detection and force limiting in human interaction zones',\r\n            'system reliability': 'Implement redundant safety systems and regular health checks'\r\n        }\r\n        \r\n        return recommendations.get(requirement, 'Consult relevant safety standard for specific requirements')\r\n\r\n# \u2139\ufe0f Safety documentation and certification \u2139\ufe0f\r\nclass SafetyDocumentation:\r\n    def __init__(self, robot_name, serial_number):\r\n        self.robot_name = robot_name\r\n        self.serial_number = serial_number\r\n        self.safety_case = {}\r\n        \r\n    def generate_safety_case(self):\r\n        \"\"\"Generate complete safety case for the robot\"\"\"\r\n        safety_case = {\r\n            'robot_identification': {\r\n                'name': self.robot_name,\r\n                'serial': self.serial_number,\r\n                'model': 'Generic Humanoid v1.0'\r\n            },\r\n            'hazard_analysis': self._perform_hazard_analysis(),\r\n            'safety_requirements': self._define_safety_requirements(),\r\n            'validation_results': self._get_validation_results(),\r\n            'residual_risks': self._identify_residual_risks(),\r\n            'safe_operating_procedures': self._define_operating_procedures()\r\n        }\r\n        \r\n        self.safety_case = safety_case\r\n        return safety_case\r\n    \r\n    def _perform_hazard_analysis(self):\r\n        \"\"\"Perform systematic hazard analysis\"\"\"\r\n        hazards = [\r\n            {\r\n                'hazard': 'Uncontrolled motion',\r\n                'hazardous_situation': 'Robot moves unexpectedly during maintenance',\r\n                'harm': 'Physical injury to personnel',\r\n                'severity': 'High',\r\n                'probability': 'Medium',\r\n                'risk_level': 'High',\r\n                'mitigation': 'Implement lockout/tagout procedures and motion interlocks'\r\n            },\r\n            {\r\n                'hazard': 'Falling',\r\n                'hazardous_situation': 'Robot loses balance during operation',\r\n                'harm': 'Robot falls onto nearby personnel or objects',\r\n                'severity': 'High',\r\n                'probability': 'Low',\r\n                'risk_level': 'Medium',\r\n                'mitigation': 'Implement balance control and fall protection systems'\r\n            },\r\n            {\r\n                'hazard': 'High contact force',\r\n                'hazardous_situation': 'Robot applies excessive force during interaction',\r\n                'harm': 'Injury during human-robot interaction',\r\n                'severity': 'Medium',\r\n                'probability': 'Low',\r\n                'risk_level': 'Low',\r\n                'mitigation': 'Implement force limiting and compliant control'\r\n            }\r\n        ]\r\n        \r\n        return hazards\r\n    \r\n    def _define_safety_requirements(self):\r\n        \"\"\"Define safety requirements based on hazard analysis\"\"\"\r\n        requirements = [\r\n            {\r\n                'id': 'SR-001',\r\n                'requirement': 'The robot shall stop all motion within 100ms of emergency stop signal',\r\n                'verification_method': 'Test with emergency stop button'\r\n            },\r\n            {\r\n                'id': 'SR-002', \r\n                'requirement': 'The robot shall maintain balance with a 5cm CoM displacement during normal operation',\r\n                'verification_method': 'Stability tests with external disturbances'\r\n            },\r\n            {\r\n                'id': 'SR-003',\r\n                'requirement': 'All joint torques shall be limited to 50 Nm during human interaction mode',\r\n                'verification_method': 'Force measurement during interaction tests'\r\n            }\r\n        ]\r\n        \r\n        return requirements\r\n    \r\n    def _get_validation_results(self):\r\n        \"\"\"Get results from safety validation and testing\"\"\"\r\n        return {\r\n            'functional_safety_tests': {\r\n                'status': 'Passed',\r\n                'date': '2024-01-15',\r\n                'test_procedure': 'SFT-001'\r\n            },\r\n            'drop_tests': {\r\n                'status': 'Passed',\r\n                'date': '2024-01-18',\r\n                'test_procedure': 'DT-002'\r\n            },\r\n            'emergy_stop_tests': {\r\n                'status': 'Passed', \r\n                'date': '2024-01-20',\r\n                'test_procedure': 'EST-003'\r\n            }\r\n        }\r\n    \r\n    def _identify_residual_risks(self):\r\n        \"\"\"Identify risks that remain after mitigation\"\"\"\r\n        residual_risks = [\r\n            {\r\n                'risk': 'Very high impact disturbance',\r\n                'residual_probability': 'Very Low',\r\n                'residual_severity': 'High',\r\n                'mitigation_status': 'Mitigated but not eliminated'\r\n            },\r\n            {\r\n                'risk': 'Software failure in safety system',\r\n                'residual_probability': 'Low',\r\n                'residual_severity': 'High',\r\n                'mitigation_status': 'Mitigated with redundant systems'\r\n            }\r\n        ]\r\n        \r\n        return residual_risks\r\n    \r\n    def _define_operating_procedures(self):\r\n        \"\"\"Define safe operating procedures\"\"\"\r\n        procedures = {\r\n            'pre_operation_checklist': [\r\n                'Verify emergency stop functionality',\r\n                'Check all joint limits and ranges of motion',\r\n                'Confirm communication with safety systems',\r\n                'Verify adequate space for operation'\r\n            ],\r\n            'normal_operation': [\r\n                'Maintain safe distance during autonomous operation',\r\n                'Monitor robot state continuously',\r\n                'Be prepared to activate emergency stop'\r\n            ],\r\n            'maintenance_mode': [\r\n                'Use lockout/tagout procedures',\r\n                'Follow proper isolation procedures',\r\n                'Verify robot is in safe pose before maintenance'\r\n            ]\r\n        }\r\n        \r\n        return procedures\r\n    \r\n    def export_certification_package(self):\r\n        \"\"\"Export safety documentation for certification\"\"\"\r\n        # This would generate proper documentation files\r\n        # suitable for safety certification\r\n        print(f\"Generating safety certification package for {self.robot_name}\")\r\n        \r\n        # In practice, this would create structured documents,\r\n        # safety reports, test records, etc. for certification bodies\r\n        return {\r\n            'safety_case_report': 'safety_case.pdf',\r\n            'test_reports': ['functional_tests.pdf', 'safety_tests.pdf'],\r\n            'risk_assessment': 'risk_assessment.pdf',\r\n            'safety_requirements': 'safety_requirements.pdf'\r\n        }\n"})}),"\n",(0,t.jsx)(n.h2,{id:"-117-summary-",children:"\ud83d\udcdd 11.7 Summary \ud83d\udcdd"}),"\n",(0,t.jsx)(n.p,{children:"Advanced humanoid control is a complex field that requires balancing multiple competing requirements: stability, mobility, safety, and efficiency. This chapter covered key aspects including:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Humanoid Kinematics & Control"}),": Understanding the unique challenges of controlling robots with human-like form factors, including complex kinematic chains and balance requirements."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Balance & Stability Control"}),": Implementing sophisticated control systems to maintain balance using ZMP control, whole-body control, and predictive approaches."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Bipedal Locomotion"}),": Generating stable walking patterns with proper foot placement, CoM control, and adaptation to different terrains."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Whole-Body Control"}),": Coordinating multiple tasks with different priorities using operational space control and task-prioritized frameworks."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Learning-Based Control"}),": Using imitation learning and reinforcement learning to acquire complex behaviors."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Validation & Testing"}),": Ensuring control systems are safe and reliable through simulation and real-world testing."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Safety Systems"}),": Implementing comprehensive safety and emergency response systems."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The field of humanoid robotics continues to evolve rapidly, with machine learning and advanced control techniques enabling ever more sophisticated behaviors."}),"\n",(0,t.jsx)(n.h3,{id:"\u2139\ufe0f-key-takeaways-\u2139\ufe0f",children:"\u2139\ufe0f Key Takeaways: \u2139\ufe0f"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Humanoid control requires specialized approaches due to the bipedal nature and high degrees of freedom"}),"\n",(0,t.jsx)(n.li,{children:"Balance control is fundamental and often achieved through ZMP-based methods"}),"\n",(0,t.jsx)(n.li,{children:"Whole-body control frameworks coordinate multiple tasks simultaneously"}),"\n",(0,t.jsx)(n.li,{children:"Learning approaches can complement traditional control methods"}),"\n",(0,t.jsx)(n.li,{children:"Safety and validation are paramount in physical AI systems"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"-knowledge-check-",children:"\ud83e\udd14 Knowledge Check \ud83e\udd14"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Explain the challenges of controlling humanoid robots compared to simpler robotic platforms."}),"\n",(0,t.jsx)(n.li,{children:"Describe how ZMP (Zero Moment Point) control contributes to bipedal stability."}),"\n",(0,t.jsx)(n.li,{children:"What are the key components of a whole-body control system for humanoid robots?"}),"\n",(0,t.jsx)(n.li,{children:"How can reinforcement learning be applied to learn complex humanoid behaviors?"}),"\n",(0,t.jsx)(n.li,{children:"What are the critical safety considerations for humanoid robots?"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsxs)(n.em,{children:["Continue to ",(0,t.jsx)(n.a,{href:"./chapter-12-capstone-autonomous-humanoid.md",children:"Chapter 12: Capstone - Autonomous Humanoid"})]})})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>a});var t=r(6540);const o={},i=t.createContext(o);function s(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);