"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[5614],{4452:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>m,frontMatter:()=>t,metadata:()=>o,toc:()=>c});var i=r(4848),s=r(8453);const t={slug:"chapter-6-simulation-gazebo-urdf-sdf",title:"Chapter 6 - Simulation with Gazebo (URDF/SDF)",description:"Comprehensive guide to simulation with Gazebo using URDF and SDF for robotics",tags:["simulation","gazebo","urdf","sdf","robotics","physics","3d"]},a="\ud83d\udcda Chapter 6: Simulation with Gazebo (URDF/SDF) \ud83d\udcda",o={id:"part-3-digital-twin/chapter-6-simulation-gazebo-urdf-sdf",title:"Chapter 6 - Simulation with Gazebo (URDF/SDF)",description:"Comprehensive guide to simulation with Gazebo using URDF and SDF for robotics",source:"@site/docusaurus/docs/part-3-digital-twin/chapter-6-simulation-gazebo-urdf-sdf.md",sourceDirName:"part-3-digital-twin",slug:"/part-3-digital-twin/chapter-6-simulation-gazebo-urdf-sdf",permalink:"/Humanoid-Robotic-Book/docs/part-3-digital-twin/chapter-6-simulation-gazebo-urdf-sdf",draft:!1,unlisted:!1,editUrl:"https://github.com/aamna847/Humanoid-Robotic-Book/edit/main/docusaurus/docs/part-3-digital-twin/chapter-6-simulation-gazebo-urdf-sdf.md",tags:[{label:"simulation",permalink:"/Humanoid-Robotic-Book/docs/tags/simulation"},{label:"gazebo",permalink:"/Humanoid-Robotic-Book/docs/tags/gazebo"},{label:"urdf",permalink:"/Humanoid-Robotic-Book/docs/tags/urdf"},{label:"sdf",permalink:"/Humanoid-Robotic-Book/docs/tags/sdf"},{label:"robotics",permalink:"/Humanoid-Robotic-Book/docs/tags/robotics"},{label:"physics",permalink:"/Humanoid-Robotic-Book/docs/tags/physics"},{label:"3d",permalink:"/Humanoid-Robotic-Book/docs/tags/3-d"}],version:"current",frontMatter:{slug:"chapter-6-simulation-gazebo-urdf-sdf",title:"Chapter 6 - Simulation with Gazebo (URDF/SDF)",description:"Comprehensive guide to simulation with Gazebo using URDF and SDF for robotics",tags:["simulation","gazebo","urdf","sdf","robotics","physics","3d"]},sidebar:"tutorialSidebar",previous:{title:"Chapter 5 - Launch Systems & Parameter Management",permalink:"/Humanoid-Robotic-Book/docs/part-2-nervous-system/chapter-5-launch-systems-parameter-management"},next:{title:"Chapter 7 - Physics Simulation & Unity Integration",permalink:"/Humanoid-Robotic-Book/docs/part-3-digital-twin/chapter-7-physics-simulation-unity-integration"}},l={},c=[{value:"\ud83c\udfaf Learning Objectives \ud83c\udfaf",id:"-learning-objectives-",level:2},{value:"\ud83d\udccb Table of Contents \ud83d\udccb",id:"-table-of-contents-",level:2},{value:"\ud83d\udc4b Introduction to Robotics Simulation \ud83d\udc4b",id:"-introduction-to-robotics-simulation-",level:2},{value:"\ud83c\udfae Primary Functions of Simulation \ud83c\udfae",id:"-primary-functions-of-simulation-",level:3},{value:"\ud83e\udd16 Simulation Challenges in Physical AI \ud83e\udd16",id:"-simulation-challenges-in-physical-ai-",level:3},{value:"\ud83c\udfae Simulation Fidelity Levels \ud83c\udfae",id:"-simulation-fidelity-levels-",level:3},{value:"\ud83c\udfae Gazebo Simulation Environment \ud83c\udfae",id:"-gazebo-simulation-environment-",level:2},{value:"\ud83c\udfd7\ufe0f Gazebo Architecture \ud83c\udfd7\ufe0f",id:"\ufe0f-gazebo-architecture-\ufe0f",level:3},{value:"\u2139\ufe0f Installing Gazebo Harmonic \u2139\ufe0f",id:"\u2139\ufe0f-installing-gazebo-harmonic-\u2139\ufe0f",level:3},{value:"\u2139\ufe0f Basic Gazebo Concepts \u2139\ufe0f",id:"\u2139\ufe0f-basic-gazebo-concepts-\u2139\ufe0f",level:3},{value:"\u2139\ufe0f Worlds \u2139\ufe0f",id:"\u2139\ufe0f-worlds-\u2139\ufe0f",level:4},{value:"\ud83c\udfd7\ufe0f Models \ud83c\udfd7\ufe0f",id:"\ufe0f-models-\ufe0f",level:4},{value:"\ud83d\udce1 Sensors in Gazebo \ud83d\udce1",id:"-sensors-in-gazebo-",level:3},{value:"\u2139\ufe0f Plugins in Gazebo \u2139\ufe0f",id:"\u2139\ufe0f-plugins-in-gazebo-\u2139\ufe0f",level:3},{value:"\ud83c\udfae Unity Simulation Environment \ud83c\udfae",id:"-unity-simulation-environment-",level:2},{value:"\ud83e\udd16 Unity for Robotics \ud83e\udd16",id:"-unity-for-robotics-",level:3},{value:"\ud83e\udd16 Unity Robotics Simulation Setup \ud83e\udd16",id:"-unity-robotics-simulation-setup-",level:3},{value:"\u2139\ufe0f Unity Scene Structure \u2139\ufe0f",id:"\u2139\ufe0f-unity-scene-structure-\u2139\ufe0f",level:3},{value:"\u2139\ufe0f Physics Configuration in Unity \u2139\ufe0f",id:"\u2139\ufe0f-physics-configuration-in-unity-\u2139\ufe0f",level:3},{value:"\ud83c\udfae Sensor Simulation in Unity \ud83c\udfae",id:"-sensor-simulation-in-unity-",level:3},{value:"\ud83c\udfae Camera Simulation \ud83c\udfae",id:"-camera-simulation-",level:4},{value:"\ud83c\udfae LiDAR Simulation \ud83c\udfae",id:"-lidar-simulation-",level:4},{value:"\ud83c\udfd7\ufe0f URDF &amp; SDF Models \ud83c\udfd7\ufe0f",id:"\ufe0f-urdf--sdf-models-\ufe0f",level:2},{value:"\u2139\ufe0f URDF Structure \u2139\ufe0f",id:"\u2139\ufe0f-urdf-structure-\u2139\ufe0f",level:3},{value:"\u2139\ufe0f SDF Structure \u2139\ufe0f",id:"\u2139\ufe0f-sdf-structure-\u2139\ufe0f",level:3},{value:"\u2139\ufe0f Xacro for URDF \u2139\ufe0f",id:"\u2139\ufe0f-xacro-for-urdf-\u2139\ufe0f",level:3},{value:"\u2139\ufe0f URDF to SDF Conversion \u2139\ufe0f",id:"\u2139\ufe0f-urdf-to-sdf-conversion-\u2139\ufe0f",level:3},{value:"\ud83c\udfae Sensor Simulation \ud83c\udfae",id:"-sensor-simulation-",level:2},{value:"\ud83c\udfae Camera Simulation \ud83c\udfae",id:"-camera-simulation--1",level:3},{value:"\ud83c\udfae LiDAR Simulation \ud83c\udfae",id:"-lidar-simulation--1",level:3},{value:"\ud83c\udfae IMU Simulation \ud83c\udfae",id:"-imu-simulation-",level:3},{value:"\ud83c\udfae Physics Simulation \ud83c\udfae",id:"-physics-simulation-",level:2},{value:"\u2139\ufe0f Physics Engine Selection \u2139\ufe0f",id:"\u2139\ufe0f-physics-engine-selection-\u2139\ufe0f",level:3},{value:"\u2139\ufe0f ODE (Open Dynamics Engine) \u2139\ufe0f",id:"\u2139\ufe0f-ode-open-dynamics-engine-\u2139\ufe0f",level:4},{value:"\u2139\ufe0f Bullet Physics \u2139\ufe0f",id:"\u2139\ufe0f-bullet-physics-\u2139\ufe0f",level:4},{value:"\u2139\ufe0f Physics Configuration \u2139\ufe0f",id:"\u2139\ufe0f-physics-configuration-\u2139\ufe0f",level:3},{value:"\u2139\ufe0f Material Properties \u2139\ufe0f",id:"\u2139\ufe0f-material-properties-\u2139\ufe0f",level:3},{value:"\ud83c\udfae Digital Twin &amp; Environment Design \ud83c\udfae",id:"-digital-twin--environment-design-",level:2},{value:"\ud83c\udf0d Creating Realistic Environments \ud83c\udf0d",id:"-creating-realistic-environments-",level:3},{value:"\ud83c\udf0d Indoor Environments \ud83c\udf0d",id:"-indoor-environments-",level:4},{value:"\ud83c\udf0d Outdoor Environments \ud83c\udf0d",id:"-outdoor-environments-",level:4},{value:"\u2139\ufe0f Environment Parameterization \u2139\ufe0f",id:"\u2139\ufe0f-environment-parameterization-\u2139\ufe0f",level:3},{value:"\ud83d\udd17 ROS 2 Integration \ud83d\udd17",id:"-ros-2-integration-",level:2},{value:"\u2139\ufe0f ROS 2 Gazebo Bridge \u2139\ufe0f",id:"\u2139\ufe0f-ros-2-gazebo-bridge-\u2139\ufe0f",level:3},{value:"\u2139\ufe0f Gazebo Services \u2139\ufe0f",id:"\u2139\ufe0f-gazebo-services-\u2139\ufe0f",level:3},{value:"\ud83c\udfae Simulation Testing &amp; Validation \ud83c\udfae",id:"-simulation-testing--validation-",level:2},{value:"\ud83c\udfae Testing Simulation Accuracy \ud83c\udfae",id:"-testing-simulation-accuracy-",level:3},{value:"\u2139\ufe0f Sim-to-Real Transfer \u2139\ufe0f",id:"\u2139\ufe0f-sim-to-real-transfer-\u2139\ufe0f",level:2},{value:"\ud83e\udd16 Domain Randomization \ud83e\udd16",id:"-domain-randomization-",level:3},{value:"\u2139\ufe0f System Identification for Parameter Tuning \u2139\ufe0f",id:"\u2139\ufe0f-system-identification-for-parameter-tuning-\u2139\ufe0f",level:3},{value:"\ud83d\udcc8 Performance Optimization \ud83d\udcc8",id:"-performance-optimization-",level:2},{value:"\ud83c\udfae Simulation Performance Strategies \ud83c\udfae",id:"-simulation-performance-strategies-",level:3},{value:"\ud83d\udcdd Chapter Summary \ud83d\udcdd",id:"-chapter-summary-",level:2},{value:"\ud83e\udd14 Knowledge Check \ud83e\udd14",id:"-knowledge-check-",level:2},{value:"\u2139\ufe0f Practical Exercise \u2139\ufe0f",id:"\u2139\ufe0f-practical-exercise-\u2139\ufe0f",level:3},{value:"\ud83d\udcac Discussion Questions \ud83d\udcac",id:"-discussion-questions-",level:3}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.h1,{id:"-chapter-6-simulation-with-gazebo-urdfsdf-",children:"\ud83d\udcda Chapter 6: Simulation with Gazebo (URDF/SDF) \ud83d\udcda"}),"\n",(0,i.jsx)(e.h2,{id:"-learning-objectives-",children:"\ud83c\udfaf Learning Objectives \ud83c\udfaf"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Understand the role of simulation in Physical AI development"}),"\n",(0,i.jsx)(e.li,{children:"Master Gazebo simulation for physics, collisions, and sensors"}),"\n",(0,i.jsx)(e.li,{children:"Learn Unity for high-fidelity visual rendering and VR/AR integration"}),"\n",(0,i.jsx)(e.li,{children:"Create and configure robot models with URDF/SDF for simulation"}),"\n",(0,i.jsx)(e.li,{children:"Implement sensor simulation with realistic parameters"}),"\n",(0,i.jsx)(e.li,{children:"Design simulation environments for physical AI training"}),"\n",(0,i.jsx)(e.li,{children:"Connect simulation to real ROS 2 systems (sim-to-real transfer)"}),"\n",(0,i.jsx)(e.li,{children:"Optimize simulation performance for training efficiency"}),"\n",(0,i.jsx)(e.li,{children:"Implement domain randomization techniques to bridge sim-to-real gap"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"-table-of-contents-",children:"\ud83d\udccb Table of Contents \ud83d\udccb"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#introduction-to-robotics-simulation",children:"Introduction to Robotics Simulation"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#gazebo-simulation-environment",children:"Gazebo Simulation Environment"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#unity-simulation-environment",children:"Unity Simulation Environment"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#urdf--sdf-models",children:"URDF & SDF Models"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#sensor-simulation",children:"Sensor Simulation"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#physics-simulation",children:"Physics Simulation"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#digital-twin--environment-design",children:"Digital Twin & Environment Design"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#ros-2-integration",children:"ROS 2 Integration"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#simulation-testing--validation",children:"Simulation Testing & Validation"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#sim-to-real-transfer",children:"Sim-to-Real Transfer"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#performance-optimization",children:"Performance Optimization"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#chapter-summary",children:"Chapter Summary"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"#knowledge-check",children:"Knowledge Check"})}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"-introduction-to-robotics-simulation-",children:"\ud83d\udc4b Introduction to Robotics Simulation \ud83d\udc4b"}),"\n",(0,i.jsx)(e.p,{children:"Simulation plays a critical role in Physical AI development by providing safe, cost-effective, and controllable environments for testing and training robotic systems. In the context of humanoid robotics, simulation is especially valuable as it allows for extensive testing of complex physical interactions without risking expensive hardware or human safety."}),"\n",(0,i.jsx)(e.h3,{id:"-primary-functions-of-simulation-",children:"\ud83c\udfae Primary Functions of Simulation \ud83c\udfae"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Algorithm Development"}),": Test new algorithms without hardware constraints"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Safety Validation"}),": Ensure robot behaviors are safe before real-world deployment"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Training Data Generation"}),": Create large datasets for machine learning applications"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Performance Evaluation"}),": Benchmark robot capabilities in controlled scenarios"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Multi-Robot Coordination"}),": Test multi-robot systems with complex interactions"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"-simulation-challenges-in-physical-ai-",children:"\ud83e\udd16 Simulation Challenges in Physical AI \ud83e\udd16"}),"\n",(0,i.jsx)(e.p,{children:"Simulation for Physical AI presents specific challenges:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Reality Gap"}),": Differences between simulated and real physics, sensors, and dynamics"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Computational Requirements"}),": Complex physics simulation demands significant computation"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Model Fidelity"}),": Balance between accuracy and performance requirements"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Transfer Learning"}),": Ensuring learned behaviors work in real-world scenarios"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"-simulation-fidelity-levels-",children:"\ud83c\udfae Simulation Fidelity Levels \ud83c\udfae"}),"\n",(0,i.jsx)(e.p,{children:"Simulation fidelity can be categorized into:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Kinematic Simulation"}),": Basic motion without physics forces"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Dynamic Simulation"}),": Includes forces, torques, and physical interactions"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sensor Simulation"}),": Realistic modeling of real sensors"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Environmental Simulation"}),": Detailed representations of real-world conditions"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"System-Level Simulation"}),": Full hardware-in-the-loop simulation"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"-gazebo-simulation-environment-",children:"\ud83c\udfae Gazebo Simulation Environment \ud83c\udfae"}),"\n",(0,i.jsx)(e.p,{children:"Gazebo is the standard simulation environment for ROS 2, providing high-fidelity physics simulation and sensor modeling specifically designed for robotics research and development."}),"\n",(0,i.jsx)(e.h3,{id:"\ufe0f-gazebo-architecture-\ufe0f",children:"\ud83c\udfd7\ufe0f Gazebo Architecture \ud83c\udfd7\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"Gazebo follows a client-server architecture:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"Gazebo Server (gzserver)\r\n\u251c\u2500\u2500 Physics Engine (ODE, Bullet, Simbody)\r\n\u251c\u2500\u2500 Sensor System\r\n\u251c\u2500\u2500 Model Database\r\n\u2514\u2500\u2500 Plugin System\r\n\r\nGazebo Client (gzclient)\r\n\u251c\u2500\u2500 Visualization\r\n\u251c\u2500\u2500 GUI Controls\r\n\u2514\u2500\u2500 Rendering (OGRE)\r\n\r\nROS 2 Bridge (ros_gz)\r\n\u251c\u2500\u2500 Topic Bridges\r\n\u251c\u2500\u2500 Service Bridges\r\n\u2514\u2500\u2500 Parameter Bridges\n"})}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-installing-gazebo-harmonic-\u2139\ufe0f",children:"\u2139\ufe0f Installing Gazebo Harmonic \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"With ROS 2 Humble, Gazebo Harmonic is included as part of the standard installation:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"# \u2139\ufe0f Install Gazebo Harmonic \u2139\ufe0f\r\nsudo apt update\r\nsudo apt install gz-harmonic\r\n\r\n# \u2139\ufe0f Install ROS 2 Gazebo bridge packages \u2139\ufe0f\r\nsudo apt install ros-humble-ros-gz\n"})}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-basic-gazebo-concepts-\u2139\ufe0f",children:"\u2139\ufe0f Basic Gazebo Concepts \u2139\ufe0f"}),"\n",(0,i.jsx)(e.h4,{id:"\u2139\ufe0f-worlds-\u2139\ufe0f",children:"\u2139\ufe0f Worlds \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"Worlds define the simulation environment:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\r\n<sdf version="1.7">\r\n  <world name="humanoid_lab">\r\n    \x3c!-- Include standard models --\x3e\r\n    <include>\r\n      <uri>model://sun</uri>\r\n    </include>\r\n    \r\n    <include>\r\n      <uri>model://ground_plane</uri>\r\n    </include>\r\n    \r\n    \x3c!-- Physics engine configuration --\x3e\r\n    <physics type="ode">\r\n      <max_step_size>0.001</max_step_size>\r\n      <real_time_factor>1.0</real_time_factor>\r\n      <real_time_update_rate>1000.0</real_time_update_rate>\r\n      <gravity>0 0 -9.8</gravity>\r\n    </physics>\r\n    \r\n    \x3c!-- Lighting --\x3e\r\n    <light name="main_light" type="directional">\r\n      <pose>0 0 10 0 0 0</pose>\r\n      <diffuse>0.8 0.8 0.8 1</diffuse>\r\n      <specular>0.2 0.2 0.2 1</specular>\r\n      <attenuation>\r\n        <range>1000</range>\r\n      </attenuation>\r\n      <direction>-0.4 0.2 -1.0</direction>\r\n    </light>\r\n    \r\n    \x3c!-- Environment Models --\x3e\r\n    <model name="table">\r\n      <pose>2 0 0 0 0 0</pose>\r\n      <link name="link">\r\n        <collision name="collision">\r\n          <geometry>\r\n            <box>\r\n              <size>1.0 0.6 0.8</size>\r\n            </box>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="visual">\r\n          <geometry>\r\n            <box>\r\n              <size>1.0 0.6 0.8</size>\r\n            </box>\r\n          </geometry>\r\n          <material>\r\n            <ambient>0.8 0.6 0.4 1</ambient>\r\n            <diffuse>0.8 0.6 0.4 1</diffuse>\r\n          </material>\r\n        </visual>\r\n        <inertial>\r\n          <mass>10.0</mass>\r\n          <inertia>\r\n            <ixx>1.0</ixx>\r\n            <ixy>0.0</ixy>\r\n            <ixz>0.0</ixz>\r\n            <iyy>1.0</iyy>\r\n            <iyz>0.0</iyz>\r\n            <izz>1.0</izz>\r\n          </inertia>\r\n        </inertial>\r\n      </link>\r\n    </model>\r\n    \r\n    \x3c!-- Robot spawn point --\x3e\r\n    <state world_name="humanoid_lab">\r\n      <model name="my_humanoid_robot">\r\n        <pose>0 0 1 0 0 0</pose>\r\n      </model>\r\n    </state>\r\n  </world>\r\n</sdf>\n'})}),"\n",(0,i.jsx)(e.h4,{id:"\ufe0f-models-\ufe0f",children:"\ud83c\udfd7\ufe0f Models \ud83c\udfd7\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"Models represent objects in the environment with:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Visual"}),": How the model appears in the simulation"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Collision"}),": Physical collision representation"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Inertial"}),": Mass properties for physics calculations"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Links"}),": Rigid bodies connected by joints"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Joints"}),": Connections between links"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sensors"}),": Simulated sensor components"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"Example model definition:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\r\n<sdf version="1.7">\r\n  <model name="humanoid_robot">\r\n    \x3c!-- Base link --\x3e\r\n    <link name="base_link">\r\n      <pose>0 0 1.0 0 0 0</pose>\r\n      \r\n      <inertial>\r\n        <mass>10.0</mass>\r\n        <inertia>\r\n          <ixx>0.1</ixx>\r\n          <ixy>0.0</ixy>\r\n          <ixz>0.0</ixz>\r\n          <iyy>0.1</iyy>\r\n          <iyz>0.0</iyz>\r\n          <izz>0.2</izz>\r\n        </inertia>\r\n      </inertial>\r\n      \r\n      <visual name="base_visual">\r\n        <geometry>\r\n          <cylinder>\r\n            <radius>0.15</radius>\r\n            <length>0.3</length>\r\n          </cylinder>\r\n        </geometry>\r\n        <material>\r\n          <ambient>0.1 0.1 0.8 1</ambient>\r\n          <diffuse>0.1 0.1 0.8 1</diffuse>\r\n        </material>\r\n      </visual>\r\n      \r\n      <collision name="base_collision">\r\n        <geometry>\r\n          <cylinder>\r\n            <radius>0.15</radius>\r\n            <length>0.3</length>\r\n          </cylinder>\r\n        </geometry>\r\n      </collision>\r\n    </link>\r\n    \r\n    \x3c!-- Hip joint --\x3e\r\n    <joint name="left_hip_joint" type="revolute">\r\n      <parent>base_link</parent>\r\n      <child>left_thigh</child>\r\n      <axis>\r\n        <xyz>0 1 0</xyz>\r\n        <limit>\r\n          <lower>-1.57</lower>\r\n          <upper>1.57</upper>\r\n          <effort>100.0</effort>\r\n          <velocity>1.0</velocity>\r\n        </limit>\r\n      </axis>\r\n      <pose>-0.1 -0.1 0 0 0 0</pose>\r\n    </joint>\r\n    \r\n    \x3c!-- Thigh link --\x3e\r\n    <link name="left_thigh">\r\n      <inertial>\r\n        <mass>2.0</mass>\r\n        <inertia>\r\n          <ixx>0.01</ixx>\r\n          <ixy>0.0</ixy>\r\n          <ixz>0.0</ixz>\r\n          <iyy>0.01</iyy>\r\n          <iyz>0.0</iyz>\r\n          <izz>0.005</izz>\r\n        </inertia>\r\n      </inertial>\r\n      \r\n      <visual name="thigh_visual">\r\n        <geometry>\r\n          <cylinder>\r\n            <radius>0.05</radius>\r\n            <length>0.4</length>\r\n          </cylinder>\r\n        </geometry>\r\n        <pose>0 0 -0.2 0 1.57 0</pose>\r\n      </visual>\r\n      \r\n      <collision name="thigh_collision">\r\n        <geometry>\r\n          <cylinder>\r\n            <radius>0.05</radius>\r\n            <length>0.4</length>\r\n          </cylinder>\r\n        </geometry>\r\n        <pose>0 0 -0.2 0 1.57 0</pose>\r\n      </collision>\r\n    </link>\r\n    \r\n    \x3c!-- Sensors --\x3e\r\n    <sensor name="rgbd_camera" type="rgbd_camera">\r\n      <pose>0.15 0 0.1 0 0 0</pose>\r\n      <camera>\r\n        <horizontal_fov>1.047</horizontal_fov>\r\n        <image>\r\n          <width>640</width>\r\n          <height>480</height>\r\n        </image>\r\n        <clip>\r\n          <near>0.1</near>\r\n          <far>10.0</far>\r\n        </clip>\r\n      </camera>\r\n    </sensor>\r\n  </model>\r\n</sdf>\n'})}),"\n",(0,i.jsx)(e.h3,{id:"-sensors-in-gazebo-",children:"\ud83d\udce1 Sensors in Gazebo \ud83d\udce1"}),"\n",(0,i.jsx)(e.p,{children:"Gazebo supports various sensor types:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Camera"}),": RGB and depth cameras"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"LiDAR"}),": 2D and 3D laser range finders"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"IMU"}),": Inertial measurement units"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"GPS"}),": Global positioning systems"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Contact"}),": Touch sensors"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Force/Torque"}),": Force and torque sensors"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sonar"}),": Ultrasonic range finders"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Ray"}),": Generic ray-based sensors"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"Example LiDAR sensor configuration:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<sensor name="front_lidar" type="gpu_lidar">\r\n  <pose>0.2 0 0.3 0 0 0</pose>\r\n  <topic>scan</topic>\r\n  <update_rate>10</update_rate>\r\n  <ray>\r\n    <scan>\r\n      <horizontal>\r\n        <samples>360</samples>\r\n        <resolution>1.0</resolution>\r\n        <min_angle>-3.14159</min_angle>  \x3c!-- -\u03c0 --\x3e\r\n        <max_angle>3.14159</max_angle>   \x3c!-- \u03c0 --\x3e\r\n      </horizontal>\r\n    </scan>\r\n    <range>\r\n      <min>0.1</min>\r\n      <max>30.0</max>\r\n      <resolution>0.01</resolution>\r\n    </range>\r\n  </ray>\r\n  <always_on>true</always_on>\r\n  <visualize>true</visualize>\r\n  <noise>\r\n    <type>gaussian</type>\r\n    <mean>0.0</mean>\r\n    <stddev>0.01</stddev>\r\n  </noise>\r\n</sensor>\n'})}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-plugins-in-gazebo-\u2139\ufe0f",children:"\u2139\ufe0f Plugins in Gazebo \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"Gazebo plugins extend functionality:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Physics plugins"}),": Custom physics behaviors"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Model plugins"}),": Model-specific behaviors"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sensor plugins"}),": Custom sensor processing"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"GUI plugins"}),": Interface enhancements"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"Example physics plugin:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<plugin name="gravity_compensator" filename="libGravityCompensator.so">\r\n  <gravity_vector>0 0 0</gravity_vector>\r\n</plugin>\n'})}),"\n",(0,i.jsx)(e.h2,{id:"-unity-simulation-environment-",children:"\ud83c\udfae Unity Simulation Environment \ud83c\udfae"}),"\n",(0,i.jsx)(e.p,{children:"Unity offers high-fidelity visual rendering and game engine features that complement Gazebo's physics simulation. Unity is increasingly used in robotics for visual realism and VR/AR integration."}),"\n",(0,i.jsx)(e.h3,{id:"-unity-for-robotics-",children:"\ud83e\udd16 Unity for Robotics \ud83e\udd16"}),"\n",(0,i.jsx)(e.p,{children:"Unity is valuable for:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"High-fidelity rendering"}),": Photo-realistic visuals for computer vision training"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"VR/AR integration"}),": Immersive teleoperation interfaces"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Synthetic data generation"}),": Training datasets with perfect ground truth"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Human-robot interaction"}),": Natural interaction environments"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Collaborative simulation"}),": Multiple users in shared virtual spaces"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"-unity-robotics-simulation-setup-",children:"\ud83e\udd16 Unity Robotics Simulation Setup \ud83e\udd16"}),"\n",(0,i.jsx)(e.p,{children:"Unity Robotics provides the Unity Robotics Simulation Package (URP) for robotics applications:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Install Unity Hub"})," and a compatible Unity Editor version"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Import the Unity Robotics Simulation Package"})," via Package Manager"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Setup ROS TCP Connector"})," for ROS 2 communication"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Configure physics settings"})," for accurate simulation"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-unity-scene-structure-\u2139\ufe0f",children:"\u2139\ufe0f Unity Scene Structure \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"A typical Unity robotics simulation includes:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Robot Prefabs"}),": Reusable robot models with components"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Environment Assets"}),": Terrain, buildings, objects"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sensor Components"}),": Camera, LiDAR, IMU simulators"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Physics Materials"}),": Friction and bounciness settings"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Lighting Settings"}),": Realistic lighting for computer vision"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"Unity C# script example for robot control:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing Unity.Robotics.ROSTCPConnector;\r\nusing RosMessageTypes.Geometry;\r\nusing RosMessageTypes.Std;\r\n\r\npublic class UnityRobotController : MonoBehaviour\r\n{\r\n    [SerializeField] private float linearSpeed = 1.0f;\r\n    [SerializeField] private float angularSpeed = 1.0f;\r\n    \r\n    private float linearVelocity = 0.0f;\r\n    private float angularVelocity = 0.0f;\r\n    \r\n    private Rigidbody rb;\r\n    \r\n    void Start()\r\n    {\r\n        rb = GetComponent<Rigidbody>();\r\n        \r\n        // Subscribe to ROS topic for velocity commands\r\n        ROSConnection.instance.Subscribe<TwistMsg>("/cmd_vel", CmdVelCallback);\r\n    }\r\n    \r\n    public void SetVelocity(float linear, float angular)\r\n    {\r\n        linearVelocity = linear;\r\n        angularVelocity = angular;\r\n    }\r\n    \r\n    void FixedUpdate()\r\n    {\r\n        // Apply movement based on velocities\r\n        Vector3 forwardMove = transform.forward * linearVelocity * linearSpeed * Time.fixedDeltaTime;\r\n        transform.position += forwardMove;\r\n        \r\n        // Apply rotation\r\n        float rotation = angularVelocity * angularSpeed * Time.fixedDeltaTime;\r\n        transform.Rotate(Vector3.up, rotation);\r\n    }\r\n    \r\n    void CmdVelCallback(TwistMsg msg)\r\n    {\r\n        SetVelocity((float)msg.linear.x, (float)msg.angular.z);\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-physics-configuration-in-unity-\u2139\ufe0f",children:"\u2139\ufe0f Physics Configuration in Unity \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"Unity's physics system can be configured for robotics:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\r\n\r\npublic class RobotPhysicsSettings : MonoBehaviour\r\n{\r\n    [Header("Friction Settings")]\r\n    public PhysicMaterial wheelMaterial;\r\n    \r\n    [Header("Joints Configuration")]\r\n    public ConfigurableJoint[] joints;\r\n    \r\n    [Header("Simulation Parameters")]\r\n    public float fixedTimestep = 0.02f;  // 50 Hz\r\n    public float maxAngularVelocity = 50f;\r\n    \r\n    void Start()\r\n    {\r\n        ConfigurePhysics();\r\n    }\r\n    \r\n    private void ConfigurePhysics()\r\n    {\r\n        // Set global physics settings\r\n        Time.fixedDeltaTime = fixedTimestep;\r\n        Physics.defaultSolverIterations = 10;\r\n        Physics.defaultSolverVelocityIterations = 20;\r\n        Physics.maxAngularVelocity = maxAngularVelocity;\r\n        \r\n        // Configure joint properties\r\n        foreach (var joint in joints)\r\n        {\r\n            joint.configuredInWorldSpace = false;\r\n            joint.projectionMode = JointProjectionMode.PositionAndRotation;\r\n            joint.projectionDistance = 0.1f;\r\n            joint.projectionAngle = 10f;\r\n            \r\n            // Configure joint limits\r\n            SoftJointLimit lowLimit = joint.lowAngularXLimit;\r\n            lowLimit.limit = -Mathf.PI / 2;  // -90 degrees\r\n            joint.lowAngularXLimit = lowLimit;\r\n            \r\n            SoftJointLimit highLimit = joint.highAngularXLimit;\r\n            highLimit.limit = Mathf.PI / 2;  // 90 degrees\r\n            joint.highAngularXLimit = highLimit;\r\n        }\r\n        \r\n        // Configure wheel material properties\r\n        if (wheelMaterial != null)\r\n        {\r\n            wheelMaterial.staticFriction = 1.0f;\r\n            wheelMaterial.dynamicFriction = 0.8f;\r\n            wheelMaterial.frictionCombine = PhysicMaterialCombine.MaximumFriction;\r\n        }\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"-sensor-simulation-in-unity-",children:"\ud83c\udfae Sensor Simulation in Unity \ud83c\udfae"}),"\n",(0,i.jsx)(e.p,{children:"Unity can simulate various sensors:"}),"\n",(0,i.jsx)(e.h4,{id:"-camera-simulation-",children:"\ud83c\udfae Camera Simulation \ud83c\udfae"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing UnityEngine.Rendering.HighDefinition;\r\n\r\npublic class UnityCameraSimulation : MonoBehaviour\r\n{\r\n    [Header("Camera Settings")]\r\n    public int imageWidth = 640;\r\n    public int imageHeight = 480;\r\n    public float fov = 60.0f;\r\n    \r\n    [Header("Noise Parameters")]\r\n    [Range(0.0f, 0.1f)] public float noiseIntensity = 0.02f;\r\n    \r\n    private Camera cam;\r\n    private RenderTexture renderTexture;\r\n    private Texture2D texture2D;\r\n    \r\n    void Start()\r\n    {\r\n        InitializeCamera();\r\n    }\r\n    \r\n    private void InitializeCamera()\r\n    {\r\n        cam = GetComponent<Camera>();\r\n        cam.fieldOfView = fov;\r\n        \r\n        // Create render texture for camera output\r\n        renderTexture = new RenderTexture(imageWidth, imageHeight, 24);\r\n        cam.targetTexture = renderTexture;\r\n        \r\n        texture2D = new Texture2D(imageWidth, imageHeight, TextureFormat.RGB24, false);\r\n    }\r\n    \r\n    // Method to capture and process camera image\r\n    public Texture2D CaptureImage()\r\n    {\r\n        // Set the camera to render to the texture\r\n        RenderTexture.active = renderTexture;\r\n        \r\n        // Render the camera\'s view\r\n        cam.Render();\r\n        \r\n        // Read from the render texture and save to texture2D\r\n        texture2D.ReadPixels(new Rect(0, 0, imageWidth, imageHeight), 0, 0);\r\n        texture2D.Apply();\r\n        \r\n        // Generate noisy version if needed\r\n        if (noiseIntensity > 0.0f)\r\n        {\r\n            AddNoiseToImage(texture2D);\r\n        }\r\n        \r\n        // Reset active render texture\r\n        RenderTexture.active = null;\r\n        \r\n        return texture2D;\r\n    }\r\n    \r\n    private void AddNoiseToImage(Texture2D tex)\r\n    {\r\n        Color[] pixels = tex.GetPixels();\r\n        \r\n        for (int i = 0; i < pixels.Length; i++)\r\n        {\r\n            float noise = Random.Range(-noiseIntensity, noiseIntensity);\r\n            pixels[i] = new Color(\r\n                Mathf.Clamp01(pixels[i].r + noise),\r\n                Mathf.Clamp01(pixels[i].g + noise),\r\n                Mathf.Clamp01(pixels[i].b + noise),\r\n                pixels[i].a\r\n            );\r\n        }\r\n        \r\n        tex.SetPixels(pixels);\r\n        tex.Apply();\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(e.h4,{id:"-lidar-simulation-",children:"\ud83c\udfae LiDAR Simulation \ud83c\udfae"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-csharp",children:'using System.Collections.Generic;\r\nusing UnityEngine;\r\n\r\npublic class UnityLidarSimulation : MonoBehaviour\r\n{\r\n    [Header("LiDAR Configuration")]\r\n    public int numberOfBeams = 360;\r\n    public float minAngle = -Mathf.PI;\r\n    public float maxAngle = Mathf.PI;\r\n    public float maxDistance = 30.0f;\r\n    public LayerMask detectionLayers;\r\n    \r\n    [Header("Noise Parameters")]\r\n    public float rangeNoiseStdDev = 0.01f;\r\n    public float angleNoiseStdDev = 0.001f;\r\n    \r\n    // Store the latest scan data\r\n    private float[] ranges;\r\n    \r\n    void Start()\r\n    {\r\n        ranges = new float[numberOfBeams];\r\n    }\r\n    \r\n    public float[] GetLaserScan()\r\n    {\r\n        for (int i = 0; i < numberOfBeams; i++)\r\n        {\r\n            float angle = Mathf.Lerp(minAngle, maxAngle, (float)i / (numberOfBeams - 1));\r\n            \r\n            // Add some noise to the angle for realistic simulation\r\n            angle += RandomGaussian(angleNoiseStdDev);\r\n            \r\n            Vector3 direction = new Vector3(Mathf.Cos(angle), 0, Mathf.Sin(angle));\r\n            \r\n            RaycastHit hit;\r\n            if (Physics.Raycast(transform.position, direction, out hit, maxDistance, detectionLayers))\r\n            {\r\n                float distance = hit.distance;\r\n                // Add noise to the range measurement\r\n                distance += RandomGaussian(rangeNoiseStdDev);\r\n                ranges[i] = Mathf.Min(distance, maxDistance);\r\n            }\r\n            else\r\n            {\r\n                ranges[i] = maxDistance;\r\n            }\r\n        }\r\n        \r\n        return ranges;\r\n    }\r\n    \r\n    private float RandomGaussian(float stdDev)\r\n    {\r\n        // Box-Muller transform for Gaussian noise\r\n        float u1 = Random.value;\r\n        float u2 = Random.value;\r\n        float gaussian = Mathf.Sqrt(-2.0f * Mathf.Log(u1)) * Mathf.Cos(2.0f * Mathf.PI * u2);\r\n        return gaussian * stdDev;\r\n    }\r\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"\ufe0f-urdf--sdf-models-\ufe0f",children:"\ud83c\udfd7\ufe0f URDF & SDF Models \ud83c\udfd7\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"URDF (Unified Robot Description Format) and SDF (Simulation Description Format) are essential for defining robot models in ROS and Gazebo respectively."}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-urdf-structure-\u2139\ufe0f",children:"\u2139\ufe0f URDF Structure \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"URDF is XML-based and defines robot kinematics and dynamics:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\r\n<robot name="humanoid_robot">\r\n  \x3c!-- Materials --\x3e\r\n  <material name="blue">\r\n    <color rgba="0.0 0.0 0.8 1.0"/>\r\n  </material>\r\n  <material name="black">\r\n    <color rgba="0.0 0.0 0.0 1.0"/>\r\n  </material>\r\n  \r\n  \x3c!-- Base link --\x3e\r\n  <link name="base_link">\r\n    <visual>\r\n      <geometry>\r\n        <cylinder radius="0.15" length="0.3"/>\r\n      </geometry>\r\n      <material name="blue"/>\r\n    </visual>\r\n    \r\n    <collision>\r\n      <geometry>\r\n        <cylinder radius="0.15" length="0.3"/>\r\n      </geometry>\r\n    </collision>\r\n    \r\n    <inertial>\r\n      <mass value="10.0"/>\r\n      <origin xyz="0 0 0" rpy="0 0 0"/>\r\n      <inertia \r\n        ixx="0.1" ixy="0.0" ixz="0.0"\r\n        iyy="0.1" iyz="0.0"\r\n        izz="0.2"/>\r\n    </inertial>\r\n  </link>\r\n  \r\n  \x3c!-- Spine joint and link --\x3e\r\n  <joint name="torso_joint" type="revolute">\r\n    <parent link="base_link"/>\r\n    <child link="torso_link"/>\r\n    <origin xyz="0 0 0.25" rpy="0 0 0"/>\r\n    <axis xyz="0 0 1"/>\r\n    <limit lower="-1.57" upper="1.57" effort="100" velocity="1"/>\r\n  </joint>\r\n  \r\n  <link name="torso_link">\r\n    <visual>\r\n      <geometry>\r\n        <box size="0.3 0.2 0.5"/>\r\n      </geometry>\r\n      <material name="black"/>\r\n    </visual>\r\n    \r\n    <collision>\r\n      <geometry>\r\n        <box size="0.3 0.2 0.5"/>\r\n      </geometry>\r\n    </collision>\r\n    \r\n    <inertial>\r\n      <mass value="5.0"/>\r\n      <origin xyz="0 0 0" rpy="0 0 0"/>\r\n      <inertia \r\n        ixx="0.2" ixy="0.0" ixz="0.0"\r\n        iyy="0.3" iyz="0.0"\r\n        izz="0.1"/>\r\n    </inertial>\r\n  </link>\r\n  \r\n  \x3c!-- Sensors --\x3e\r\n  <gazebo reference="base_link">\r\n    <sensor type="camera" name="rgbd_camera">\r\n      <pose>0.15 0 0.1 0 0 0</pose>\r\n      <camera>\r\n        <horizontal_fov>1.047</horizontal_fov>\r\n        <image>\r\n          <width>640</width>\r\n          <height>480</height>\r\n        </image>\r\n        <clip>\r\n          <near>0.1</near>\r\n          <far>10</far>\r\n        </clip>\r\n      </camera>\r\n      <always_on>true</always_on>\r\n      <update_rate>30.0</update_rate>\r\n      <visualize>true</visualize>\r\n    </sensor>\r\n  </gazebo>\r\n</robot>\n'})}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-sdf-structure-\u2139\ufe0f",children:"\u2139\ufe0f SDF Structure \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"SDF is more comprehensive and includes both robot and environment descriptions:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\r\n<sdf version="1.7">\r\n  <model name="humanoid_with_urdf">\r\n    <include>\r\n      <uri>model://humanoid_robot/model.urdf</uri>\r\n      <pose>0 0 1.0 0 0 0</pose>\r\n    </include>\r\n    \r\n    \x3c!-- Add more links and joints if needed --\x3e\r\n    <link name="head_link">\r\n      <pose>0 0 0.15 0 0 0</pose>\r\n      <inertial>\r\n        <mass>2.0</mass>\r\n        <inertia>\r\n          <ixx>0.01</ixx>\r\n          <ixy>0.0</ixy>\r\n          <ixz>0.0</ixz>\r\n          <iyy>0.01</iyy>\r\n          <iyz>0.0</iyz>\r\n          <izz>0.01</izz>\r\n        </inertia>\r\n      </inertial>\r\n      \r\n      <visual name="head_visual">\r\n        <geometry>\r\n          <sphere>\r\n            <radius>0.1</radius>\r\n          </sphere>\r\n        </geometry>\r\n        <material>\r\n          <ambient>0.8 0.8 0.8 1</ambient>\r\n          <diffuse>0.8 0.8 0.8 1</diffuse>\r\n        </material>\r\n      </visual>\r\n      \r\n      <collision name="head_collision">\r\n        <geometry>\r\n          <sphere>\r\n            <radius>0.1</radius>\r\n          </sphere>\r\n        </geometry>\r\n      </collision>\r\n    </link>\r\n    \r\n    <joint name="neck_joint" type="ball">\r\n      <parent>torso_link</parent>\r\n      <child>head_link</child>\r\n      <pose>0 0 0.25 0 0 0</pose>\r\n    </joint>\r\n  </model>\r\n</sdf>\n'})}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-xacro-for-urdf-\u2139\ufe0f",children:"\u2139\ufe0f Xacro for URDF \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"Xacro is a macro language for URDF that allows for reusable robot definitions:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\r\n<robot xmlns:xacro="http://www.ros.org/wiki/xacro" name="humanoid_robot">\r\n  \r\n  \x3c!-- Define properties --\x3e\r\n  <xacro:property name="M_PI" value="3.1415926535897931" />\r\n  <xacro:property name="wheel_radius" value="0.05" />\r\n  <xacro:property name="wheel_width" value="0.02" />\r\n  <xacro:property name="base_mass" value="10.0" />\r\n  \r\n  \x3c!-- Macro for wheel --\x3e\r\n  <xacro:macro name="wheel" params="prefix parent xyz joint_limit_position joint_limit_velocity effort velocity">\r\n    <joint name="${prefix}_wheel_joint" type="continuous">\r\n      <parent link="${parent}"/>\r\n      <child link="${prefix}_wheel_link"/>\r\n      <origin xyz="${xyz}" rpy="0 0 0"/>\r\n      <axis xyz="0 1 0"/>\r\n      <limit effort="${effort}" velocity="${velocity}"/>\r\n    </joint>\r\n    \r\n    <link name="${prefix}_wheel_link">\r\n      <visual>\r\n        <geometry>\r\n          <cylinder radius="${wheel_radius}" length="${wheel_width}"/>\r\n        </geometry>\r\n        <material name="black"/>\r\n      </visual>\r\n      <collision>\r\n        <geometry>\r\n          <cylinder radius="${wheel_radius}" length="${wheel_width}"/>\r\n        </geometry>\r\n      </collision>\r\n      <inertial>\r\n        <mass value="${wheel_radius * 2}"/>\r\n        <inertia \r\n          ixx="${wheel_radius * 0.5}" ixy="0" ixz="0"\r\n          iyy="${wheel_radius * 0.25}" iyz="0"\r\n          izz="${wheel_radius * 0.5}"/>\r\n      </inertial>\r\n    </link>\r\n  </xacro:macro>\r\n  \r\n  \x3c!-- Include the wheel macro twice --\x3e\r\n  <xacro:wheel prefix="left" parent="base_link" \r\n                xyz="0 0.1 0" \r\n                effort="100" velocity="1"/>\r\n  <xacro:wheel prefix="right" parent="base_link" \r\n                xyz="0 -0.1 0" \r\n                effort="100" velocity="1"/>\r\n  \r\n</robot>\n'})}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-urdf-to-sdf-conversion-\u2139\ufe0f",children:"\u2139\ufe0f URDF to SDF Conversion \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"When using URDF models in Gazebo, they get converted to SDF internally:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"# \u2139\ufe0f Convert URDF to SDF \u2139\ufe0f\r\ngz sdf -p robot.urdf > robot.sdf\r\n\r\n# \u2139\ufe0f Or use the ROS 2 utility \u2139\ufe0f\r\nros2 run xacro xacro robot.urdf.xacro > robot.urdf\n"})}),"\n",(0,i.jsx)(e.h2,{id:"-sensor-simulation-",children:"\ud83c\udfae Sensor Simulation \ud83c\udfae"}),"\n",(0,i.jsx)(e.p,{children:"Accurate sensor simulation is crucial for Physical AI development:"}),"\n",(0,i.jsx)(e.h3,{id:"-camera-simulation--1",children:"\ud83c\udfae Camera Simulation \ud83c\udfae"}),"\n",(0,i.jsx)(e.p,{children:"Camera sensors in simulation should match real-world properties:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<sensor name="camera" type="camera">\r\n  <pose>0.2 0 0.3 0 0 0</pose>\r\n  <topic>camera/image_raw</topic>\r\n  <update_rate>30</update_rate>\r\n  <camera name="head_camera">\r\n    <horizontal_fov>1.047</horizontal_fov> \x3c!-- 60 degrees --\x3e\r\n    <image>\r\n      <width>1280</width>\r\n      <height>720</height>\r\n      <format>R8G8B8</format>\r\n    </image>\r\n    <clip>\r\n      <near>0.1</near>\r\n      <far>10.0</far>\r\n    </clip>\r\n    <noise>\r\n      <type>gaussian</type>\r\n      <mean>0.0</mean>\r\n      <stddev>0.007</stddev>\r\n    </noise>\r\n  </camera>\r\n  <always_on>true</always_on>\r\n  <visualize>true</visualize>\r\n</sensor>\n'})}),"\n",(0,i.jsx)(e.h3,{id:"-lidar-simulation--1",children:"\ud83c\udfae LiDAR Simulation \ud83c\udfae"}),"\n",(0,i.jsx)(e.p,{children:"LiDAR simulation requires careful consideration of physical properties:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<sensor name="3d_lidar" type="gpu_lidar">\r\n  <pose>0.15 0 0.5 0 0 0</pose>\r\n  <topic>scan_3d</topic>\r\n  <update_rate>10</update_rate>\r\n  <ray>\r\n    <scan>\r\n      <horizontal>\r\n        <samples>1080</samples>\r\n        <resolution>1</resolution>\r\n        <min_angle>-3.14159</min_angle> \x3c!-- -\u03c0 --\x3e\r\n        <max_angle>3.14159</max_angle>  \x3c!-- \u03c0 --\x3e\r\n      </horizontal>\r\n      <vertical>\r\n        <samples>64</samples>\r\n        <resolution>1</resolution>\r\n        <min_angle>-0.261799</min_angle> \x3c!-- -15 degrees --\x3e\r\n        <max_angle>0.261799</max_angle>  \x3c!-- 15 degrees --\x3e\r\n      </vertical>\r\n    </scan>\r\n    <range>\r\n      <min>0.1</min>\r\n      <max>25.0</max>\r\n      <resolution>0.01</resolution>\r\n    </range>\r\n  </ray>\r\n  <always_on>true</always_on>\r\n  <visualize>true</visualize>\r\n  <noise>\r\n    <type>gaussian</type>\r\n    <mean>0.0</mean>\r\n    <stddev>0.01</stddev>\r\n  </noise>\r\n</sensor>\n'})}),"\n",(0,i.jsx)(e.h3,{id:"-imu-simulation-",children:"\ud83c\udfae IMU Simulation \ud83c\udfae"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<sensor name="imu_sensor" type="imu">\r\n  <pose>0 0 0.5 0 0 0</pose>\r\n  <topic>imu</topic>\r\n  <update_rate>100</update_rate>\r\n  <always_on>true</always_on>\r\n  <imu>\r\n    <angular_velocity>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>2e-4</stddev>\r\n        </noise>\r\n      </x>\r\n      <y>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>2e-4</stddev>\r\n        </noise>\r\n      </y>\r\n      <z>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>2e-4</stddev>\r\n        </noise>\r\n      </z>\r\n    </angular_velocity>\r\n    <linear_acceleration>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>1.7e-2</stddev>\r\n        </noise>\r\n      </x>\r\n      <y>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>1.7e-2</stddev>\r\n        </noise>\r\n      </y>\r\n      <z>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>1.7e-2</stddev>\r\n        </noise>\r\n      </z>\r\n    </linear_acceleration>\r\n  </imu>\r\n</sensor>\n'})}),"\n",(0,i.jsx)(e.h2,{id:"-physics-simulation-",children:"\ud83c\udfae Physics Simulation \ud83c\udfae"}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-physics-engine-selection-\u2139\ufe0f",children:"\u2139\ufe0f Physics Engine Selection \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"Different physics engines offer different trade-offs:"}),"\n",(0,i.jsx)(e.h4,{id:"\u2139\ufe0f-ode-open-dynamics-engine-\u2139\ufe0f",children:"\u2139\ufe0f ODE (Open Dynamics Engine) \u2139\ufe0f"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Used by default in Gazebo"}),"\n",(0,i.jsx)(e.li,{children:"Good for general-purpose simulation"}),"\n",(0,i.jsx)(e.li,{children:"Conservative but stable"}),"\n",(0,i.jsx)(e.li,{children:"Good for ground vehicles and basic manipulation"}),"\n"]}),"\n",(0,i.jsx)(e.h4,{id:"\u2139\ufe0f-bullet-physics-\u2139\ufe0f",children:"\u2139\ufe0f Bullet Physics \u2139\ufe0f"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Faster than ODE"}),"\n",(0,i.jsx)(e.li,{children:"Better for complex contact scenarios"}),"\n",(0,i.jsx)(e.li,{children:"Good for humanoid robots and bipedal locomotion"}),"\n",(0,i.jsx)(e.li,{children:"More complex contact modeling"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-physics-configuration-\u2139\ufe0f",children:"\u2139\ufe0f Physics Configuration \u2139\ufe0f"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<physics type="bullet">\r\n  <max_step_size>0.001</max_step_size>\r\n  <real_time_factor>1.0</real_time_factor>\r\n  <real_time_update_rate>1000.0</real_time_update_rate>\r\n  <gravity>0 0 -9.8</gravity>\r\n  \r\n  <bullet>\r\n    <solver>\r\n      <type>sequential_impulse</type>\r\n      <iters>50</iters>\r\n      <sor>1.3</sor>\r\n    </solver>\r\n    <constraints>\r\n      <contact_surface_layer>0.001</contact_surface_layer>\r\n      <contact_max_correcting_vel>100.0</contact_max_correcting_vel>\r\n      <cfm>0.0</cfm>\r\n      <erp>0.2</erp>\r\n      <contact_erp>0.2</contact_erp>\r\n      <contact_cfm>0.0</contact_cfm>\r\n    </constraints>\r\n  </bullet>\r\n</physics>\n'})}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-material-properties-\u2139\ufe0f",children:"\u2139\ufe0f Material Properties \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"Accurate material properties are essential for realistic simulation:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<material name="rubber_wheel">\r\n  <pbr>\r\n    <metal>\r\n      <albedo_map>materials/textures/rubber_color.png</albedo_map>\r\n      <roughness>0.8</roughness>\r\n      <metalness>0.0</metalness>\r\n    </metal>\r\n  </pbr>\r\n</material>\r\n\r\n\x3c!-- Physically-based friction model --\x3e\r\n<gazebo reference="wheel_link">\r\n  <mu1>1.0</mu1>  \x3c!-- Primary friction coefficient --\x3e\r\n  <mu2>1.0</mu2>  \x3c!-- Secondary friction coefficient --\x3e\r\n  <kp>1000000.0</kp>  \x3c!-- Contact stiffness --\x3e\r\n  <kd>100.0</kd>    \x3c!-- Damping coefficient --\x3e\r\n  <max_vel>100.0</max_vel>\r\n  <min_depth>0.001</min_depth>\r\n</gazebo>\n'})}),"\n",(0,i.jsx)(e.h2,{id:"-digital-twin--environment-design-",children:"\ud83c\udfae Digital Twin & Environment Design \ud83c\udfae"}),"\n",(0,i.jsx)(e.h3,{id:"-creating-realistic-environments-",children:"\ud83c\udf0d Creating Realistic Environments \ud83c\udf0d"}),"\n",(0,i.jsx)(e.p,{children:"Digital twins require careful environment design to maximize training effectiveness:"}),"\n",(0,i.jsx)(e.h4,{id:"-indoor-environments-",children:"\ud83c\udf0d Indoor Environments \ud83c\udf0d"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<sdf version="1.7">\r\n  <world name="humanoid_laboratory">\r\n    \x3c!-- Include standard models --\x3e\r\n    <include>\r\n      <uri>model://sun</uri>\r\n    </include>\r\n    <include>\r\n      <uri>model://ground_plane</uri>\r\n    </include>\r\n    \r\n    \x3c!-- Laboratory setup --\x3e\r\n    <model name="workbench">\r\n      <pose>2 0 0 0 0 0</pose>\r\n      <link name="workbench_link">\r\n        <collision name="collision">\r\n          <geometry>\r\n            <box>\r\n              <size>1.2 0.6 0.8</size>\r\n            </box>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="visual">\r\n          <geometry>\r\n            <box>\r\n              <size>1.2 0.6 0.8</size>\r\n            </box>\r\n          </geometry>\r\n          <material>\r\n            <ambient>0.6 0.4 0.2 1</ambient>\r\n            <diffuse>0.8 0.6 0.4 1</diffuse>\r\n          </material>\r\n        </visual>\r\n      </link>\r\n    </model>\r\n    \r\n    \x3c!-- Objects for manipulation --\x3e\r\n    <model name="red_box">\r\n      <pose>2.2 0.1 0.9 0 0 0</pose>\r\n      <link name="box_link">\r\n        <collision name="collision">\r\n          <geometry>\r\n            <box>\r\n              <size>0.1 0.1 0.1</size>\r\n            </box>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="visual">\r\n          <geometry>\r\n            <box>\r\n              <size>0.1 0.1 0.1</size>\r\n            </box>\r\n          </geometry>\r\n          <material>\r\n            <ambient>0.8 0.2 0.2 1</ambient>\r\n            <diffuse>1.0 0.3 0.3 1</diffuse>\r\n          </material>\r\n        </visual>\r\n        <inertial>\r\n          <mass>0.1</mass>\r\n          <inertia>\r\n            <ixx>0.00017</ixx>\r\n            <ixy>0.0</ixy>\r\n            <ixz>0.0</ixz>\r\n            <iyy>0.00017</iyy>\r\n            <iyz>0.0</iyz>\r\n            <izz>0.00017</izz>\r\n          </inertia>\r\n        </inertial>\r\n      </link>\r\n    </model>\r\n    \r\n    \x3c!-- Room with obstacles --\x3e\r\n    <model name="obstacle_course">\r\n      <pose>0 3 0 0 0 0</pose>\r\n      \x3c!-- Add various obstacles to challenge navigation --\x3e\r\n    </model>\r\n  </world>\r\n</sdf>\n'})}),"\n",(0,i.jsx)(e.h4,{id:"-outdoor-environments-",children:"\ud83c\udf0d Outdoor Environments \ud83c\udf0d"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<sdf version="1.7">\r\n  <world name="outdoor_park">\r\n    <include>\r\n      <uri>model://sun</uri>\r\n    </include>\r\n    \r\n    \x3c!-- Terraced terrain --\x3e\r\n    <model name="Terrain">\r\n      <static>true</static>\r\n      <link name="terrain_link">\r\n        <collision name="collision">\r\n          <geometry>\r\n            <heightmap>\r\n              <uri>model://outdoor_park/materials/textures/terrain.png</uri>\r\n              <size>100 100 10</size>\r\n              <pos>0 0 0</pos>\r\n            </heightmap>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="visual">\r\n          <geometry>\r\n            <heightmap>\r\n              <uri>model://outdoor_park/materials/textures/terrain.png</uri>\r\n              <size>100 100 10</size>\r\n              <pos>0 0 0</pos>\r\n            </heightmap>\r\n          </geometry>\r\n        </visual>\r\n      </link>\r\n    </model>\r\n    \r\n    \x3c!-- Walking path --\x3e\r\n    <model name="walking_path">\r\n      <static>true</static>\r\n      <link name="path_link">\r\n        <collision name="collision">\r\n          <geometry>\r\n            <mesh>\r\n              <uri>model://outdoor_park/meshes/path.dae</uri>\r\n            </mesh>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="visual">\r\n          <geometry>\r\n            <mesh>\r\n              <uri>model://outdoor_park/meshes/path.dae</uri>\r\n            </mesh>\r\n          </geometry>\r\n          <material>\r\n            <ambient>0.6 0.6 0.6 1</ambient>\r\n            <diffuse>0.7 0.7 0.7 1</diffuse>\r\n          </material>\r\n        </visual>\r\n      </link>\r\n    </model>\r\n  </world>\n'})}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-environment-parameterization-\u2139\ufe0f",children:"\u2139\ufe0f Environment Parameterization \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"For Physical AI training, environments should be parameterizable:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'<sdf version="1.7">\r\n  <world name="parametrized_environment">\r\n    \r\n    \x3c!-- Include with custom parameters --\x3e\r\n    <model name="configurable_room">\r\n      <sdf version="1.7">\r\n        <model name="room_with_params" name="{room_name}">\r\n          <link name="floor">\r\n            <collision name="collision">\r\n              <geometry>\r\n                <box>\r\n                  <size>{{room_length}} {{room_width}} 0.1</size>\r\n                </box>\r\n              </geometry>\r\n            </collision>\r\n            <visual name="visual">\r\n              <geometry>\r\n                <box>\r\n                  <size>{{room_length}} {{room_width}} 0.1</size>\r\n                </box>\r\n              </geometry>\r\n              <material>\r\n                <ambient>0.7 0.7 0.7 1</ambient>\r\n                <diffuse>0.8 0.8 0.8 1</diffuse>\r\n              </material>\r\n            </visual>\r\n          </link>\r\n          \r\n          \x3c!-- Parametrized objects --\x3e\r\n          <model name="table_1">\r\n            <pose>{{table_1_x}} {{table_1_y}} 0 0 0 0</pose>\r\n            <link name="table_link">\r\n              <collision name="collision">\r\n                <geometry>\r\n                  <box>\r\n                    <size>{{table_length}} {{table_width}} {{table_height}}</size>\r\n                  </box>\r\n                </geometry>\r\n              </collision>\r\n            </link>\r\n          </model>\r\n        </model>\r\n      </sdf>\r\n    </model>\r\n  </world>\r\n</sdf>\n'})}),"\n",(0,i.jsx)(e.h2,{id:"-ros-2-integration-",children:"\ud83d\udd17 ROS 2 Integration \ud83d\udd17"}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-ros-2-gazebo-bridge-\u2139\ufe0f",children:"\u2139\ufe0f ROS 2 Gazebo Bridge \u2139\ufe0f"}),"\n",(0,i.jsxs)(e.p,{children:["The ",(0,i.jsx)(e.code,{children:"ros_gz"})," bridge enables communication between ROS 2 and Gazebo:"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import rclpy\r\nfrom rclpy.node import Node\r\nfrom geometry_msgs.msg import Twist\r\nfrom sensor_msgs.msg import LaserScan, Image, Imu\r\nfrom nav_msgs.msg import Odometry\r\nfrom tf2_ros import TransformBroadcaster\r\nimport tf2_geometry_msgs\r\n\r\nclass RobotSimulator(Node):\r\n    def __init__(self):\r\n        super().__init__(\'robot_simulator\')\r\n        \r\n        # Subscribe to velocity commands\r\n        self.cmd_vel_sub = self.create_subscription(\r\n            Twist, \'cmd_vel\', self.cmd_vel_callback, 10\r\n        )\r\n        \r\n        # Publishers for sensor data\r\n        self.scan_pub = self.create_publisher(LaserScan, \'scan\', 10)\r\n        self.imu_pub = self.create_publisher(Imu, \'imu\', 10)\r\n        self.odom_pub = self.create_publisher(Odometry, \'odom\', 10)\r\n        \r\n        # TF broadcaster\r\n        self.tf_broadcaster = TransformBroadcaster(self)\r\n        \r\n        # Robot state\r\n        self.position = [0.0, 0.0, 0.0]\r\n        self.velocity = [0.0, 0.0, 0.0]  # x, y, theta\r\n        self.linear_cmd = 0.0\r\n        self.angular_cmd = 0.0\r\n        \r\n        # Timer for physics update\r\n        self.timer = self.create_timer(0.01, self.update_physics)  # 100Hz\r\n        \r\n        self.get_logger().info(\'Robot Simulator Node Initialized\')\r\n    \r\n    def cmd_vel_callback(self, msg):\r\n        """Process velocity commands from ROS 2"""\r\n        self.linear_cmd = msg.linear.x\r\n        self.angular_cmd = msg.angular.z\r\n    \r\n    def update_physics(self):\r\n        """Simple differential drive physics model"""\r\n        dt = 0.01  # 100Hz\r\n        \r\n        # Update velocity based on commands (with some smoothing)\r\n        self.velocity[0] += (self.linear_cmd - self.velocity[0]) * 0.1\r\n        self.velocity[2] += (self.angular_cmd - self.velocity[2]) * 0.1\r\n        \r\n        # Update position\r\n        self.position[0] += self.velocity[0] * math.cos(self.position[2]) * dt\r\n        self.position[1] += self.velocity[0] * math.sin(self.position[2]) * dt\r\n        self.position[2] += self.velocity[2] * dt\r\n        \r\n        # Publish odometry\r\n        self.publish_odometry()\r\n        \r\n        # Simulate sensors\r\n        self.simulate_lidar()\r\n        self.simulate_imu()\r\n    \r\n    def publish_odometry(self):\r\n        """Publish odometry information"""\r\n        msg = Odometry()\r\n        msg.header.stamp = self.get_clock().now().to_msg()\r\n        msg.header.frame_id = \'odom\'\r\n        msg.child_frame_id = \'base_link\'\r\n        \r\n        # Position\r\n        msg.pose.pose.position.x = self.position[0]\r\n        msg.pose.pose.position.y = self.position[1]\r\n        msg.pose.pose.position.z = 0.0\r\n        \r\n        # Convert Euler to Quaternion\r\n        quat = tf_transformations.quaternion_from_euler(0, 0, self.position[2])\r\n        msg.pose.pose.orientation.x = quat[0]\r\n        msg.pose.pose.orientation.y = quat[1]\r\n        msg.pose.pose.orientation.z = quat[2]\r\n        msg.pose.pose.orientation.w = quat[3]\r\n        \r\n        # Velocities\r\n        msg.twist.twist.linear.x = self.velocity[0]\r\n        msg.twist.twist.angular.z = self.velocity[2]\r\n        \r\n        self.odom_pub.publish(msg)\r\n        \r\n        # Broadcast transform\r\n        t = TransformStamped()\r\n        t.header.stamp = self.get_clock().now().to_msg()\r\n        t.header.frame_id = \'odom\'\r\n        t.child_frame_id = \'base_link\'\r\n        t.transform.translation.x = self.position[0]\r\n        t.transform.translation.y = self.position[1]\r\n        t.transform.translation.z = 0.0\r\n        t.transform.rotation.x = quat[0]\r\n        t.transform.rotation.y = quat[1]\r\n        t.transform.rotation.z = quat[2]\r\n        t.transform.rotation.w = quat[3]\r\n        \r\n        self.tf_broadcaster.sendTransform(t)\r\n    \r\n    def simulate_lidar(self):\r\n        """Publish simulated LiDAR data"""\r\n        msg = LaserScan()\r\n        msg.header.stamp = self.get_clock().now().to_msg()\r\n        msg.header.frame_id = \'laser_link\'\r\n        \r\n        # Set parameters\r\n        msg.angle_min = -math.pi\r\n        msg.angle_max = math.pi\r\n        msg.angle_increment = 2 * math.pi / 360\r\n        msg.range_min = 0.05\r\n        msg.range_max = 30.0\r\n        \r\n        # Generate simulated ranges based on position in environment\r\n        ranges = []\r\n        for i in range(360):\r\n            angle = msg.angle_min + i * msg.angle_increment\r\n            simulated_range = self.compute_lidar_range(angle)\r\n            ranges.append(simulated_range)\r\n        \r\n        msg.ranges = ranges\r\n        self.scan_pub.publish(msg)\r\n    \r\n    def compute_lidar_range(self, angle_in_robot_frame):\r\n        """Compute what the LiDAR would see at a given angle"""\r\n        # This would need to interface with the Gazebo environment\r\n        # For this example, we\'ll simulate a simple environment\r\n        world_angle = self.position[2] + angle_in_robot_frame\r\n        cos_world = math.cos(world_angle)\r\n        sin_world = math.sin(world_angle)\r\n        \r\n        # Simulate objects in environment\r\n        # In a real implementation, this would use Gazebo\'s scene information\r\n        simulated_distance = 10.0  # Default max range\r\n        \r\n        # Example: simulate a wall at x = 5.0\r\n        if abs(cos_world) > 0.1:\r\n            dist_to_wall = (5.0 - self.position[0]) / cos_world\r\n            if 0.1 < dist_to_wall < simulated_distance:\r\n                simulated_distance = dist_to_wall\r\n        \r\n        # Add noise\r\n        noise = random.uniform(-0.05, 0.05)\r\n        return max(0.1, simulated_distance + noise)\r\n    \r\n    def simulate_imu(self):\r\n        """Publish simulated IMU data"""\r\n        msg = Imu()\r\n        msg.header.stamp = self.get_clock().now().to_msg()\r\n        msg.header.frame_id = \'imu_link\'\r\n        \r\n        # Orientation (from robot position)\r\n        quat = tf_transformations.quaternion_from_euler(0, 0, self.position[2])\r\n        msg.orientation.x = quat[0]\r\n        msg.orientation.y = quat[1]\r\n        msg.orientation.z = quat[2]\r\n        msg.orientation.w = quat[3]\r\n        \r\n        # Angular velocity (from robot motion)\r\n        msg.angular_velocity.z = self.velocity[2]  # Turning rate\r\n        \r\n        # Linear acceleration (simplified)\r\n        msg.linear_acceleration.x = self.linear_cmd  # Commanded acceleration\r\n        \r\n        self.imu_pub.publish(msg)\n'})}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-gazebo-services-\u2139\ufe0f",children:"\u2139\ufe0f Gazebo Services \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"Gazebo provides services for simulation control:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"from rclpy.node import Node\r\nfrom rclpy.action import ActionClient\r\nfrom std_srvs.srv import Empty\r\nfrom gazebo_msgs.srv import SpawnEntity, DeleteEntity, GetEntityState, SetEntityState\r\nfrom geometry_msgs.msg import Pose, Twist\r\n\r\nclass SimulationManager(Node):\r\n    def __init__(self):\r\n        super().__init__('simulation_manager')\r\n        \r\n        # Connect to Gazebo services\r\n        self.spawn_client = self.create_client(SpawnEntity, '/spawn_entity')\r\n        self.delete_client = self.create_client(DeleteEntity, '/delete_entity')\r\n        self.get_state_client = self.create_client(GetEntityState, '/get_entity_state')\r\n        self.set_state_client = self.create_client(SetEntityState, '/set_entity_state')\r\n        \r\n        # Wait for services\r\n        while not self.spawn_client.wait_for_service(timeout_sec=1.0):\r\n            self.get_logger().info('Spawn entity service not available, waiting again...')\r\n        \r\n        while not self.delete_client.wait_for_service(timeout_sec=1.0):\r\n            self.get_logger().info('Delete entity service not available, waiting again...')\r\n    \r\n    def spawn_robot(self, robot_name, robot_xml, initial_pose):\r\n        \"\"\"Spawn a robot in the simulation\"\"\"\r\n        req = SpawnEntity.Request()\r\n        req.name = robot_name\r\n        req.xml = robot_xml\r\n        req.initial_pose = initial_pose\r\n        \r\n        future = self.spawn_client.call_async(req)\r\n        rclpy.spin_until_future_complete(self, future)\r\n        \r\n        result = future.result()\r\n        if result.success:\r\n            self.get_logger().info(f'Successfully spawned {robot_name}')\r\n        else:\r\n            self.get_logger().error(f'Failed to spawn {robot_name}: {result.status_message}')\r\n        \r\n        return result.success\r\n    \r\n    def reset_simulation(self):\r\n        \"\"\"Reset the simulation to initial state\"\"\"\r\n        reset_req = Empty.Request()\r\n        reset_client = self.create_client(Empty, '/reset_simulation')\r\n        \r\n        while not reset_client.wait_for_service(timeout_sec=1.0):\r\n            self.get_logger().info('Reset service not available, waiting again...')\r\n        \r\n        future = reset_client.call_async(reset_req)\r\n        rclpy.spin_until_future_complete(self, future)\r\n        \r\n        self.get_logger().info('Simulation reset complete')\n"})}),"\n",(0,i.jsx)(e.h2,{id:"-simulation-testing--validation-",children:"\ud83c\udfae Simulation Testing & Validation \ud83c\udfae"}),"\n",(0,i.jsx)(e.h3,{id:"-testing-simulation-accuracy-",children:"\ud83c\udfae Testing Simulation Accuracy \ud83c\udfae"}),"\n",(0,i.jsx)(e.p,{children:"It's crucial to validate that simulations accurately represent real-world behavior:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import unittest\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom geometry_msgs.msg import Twist\r\nfrom nav_msgs.msg import Odometry\r\nfrom sensor_msgs.msg import JointState\r\nimport time\r\n\r\nclass SimulationAccuracyTest(unittest.TestCase):\r\n    def setUp(self):\r\n        rclpy.init()\r\n        self.node = TestAccuracyNode()\r\n        self.executor = rclpy.executors.SingleThreadedExecutor()\r\n        self.executor.add_node(self.node)\r\n    \r\n    def tearDown(self):\r\n        self.node.destroy_node()\r\n        rclpy.shutdown()\r\n    \r\n    def test_kinematic_accuracy(self):\r\n        """Test that simulated kinematics match expected values"""\r\n        # Send a known command to the robot\r\n        cmd_msg = Twist()\r\n        cmd_msg.linear.x = 1.0  # Move forward at 1 m/s\r\n        self.node.cmd_pub.publish(cmd_msg)\r\n        \r\n        # Wait for physics to update\r\n        time.sleep(2.0)  # Move for 2 seconds\r\n        \r\n        # Check that position changed by expected amount (with tolerance)\r\n        expected_x = 2.0  # 1 m/s * 2 s\r\n        actual_x = self.node.current_pos_x\r\n        tolerance = 0.1  # 10 cm tolerance\r\n        \r\n        self.assertAlmostEqual(expected_x, actual_x, delta=tolerance,\r\n                              msg=f"Expected x={expected_x}, got x={actual_x}")\r\n    \r\n    def test_dynamic_response(self):\r\n        """Test that simulated dynamics respond appropriately"""\r\n        # Send impulse command\r\n        cmd_msg = Twist()\r\n        cmd_msg.linear.x = 2.0  # Strong forward command\r\n        self.node.cmd_pub.publish(cmd_msg)\r\n        \r\n        # Wait and check if velocity increases appropriately\r\n        time.sleep(0.5)\r\n        initial_vel = self.node.current_vel_x\r\n        \r\n        # Remove command and check for gradual decrease (due to damping)\r\n        zero_cmd = Twist()\r\n        self.node.cmd_pub.publish(zero_cmd)\r\n        \r\n        time.sleep(1.0)\r\n        final_vel = self.node.current_vel_x\r\n        \r\n        # Velocity should be lower than initial after removing command\r\n        self.assertLess(final_vel, initial_vel,\r\n                       msg="Velocity did not decrease after removing command")\r\n    \r\n    def test_sensor_consistency(self):\r\n        """Test that sensor readings are consistent with robot state"""\r\n        # Publish known robot state\r\n        # Check that sensors return expected values\r\n        \r\n        # Implementation would depend on specific sensor testing needs\r\n        pass\r\n\r\nclass TestAccuracyNode(Node):\r\n    def __init__(self):\r\n        super().__init__(\'test_accuracy_node\')\r\n        \r\n        # Publishers and subcribers for testing\r\n        self.cmd_pub = self.create_publisher(Twist, \'cmd_vel\', 10)\r\n        self.odom_sub = self.create_subscription(Odometry, \'odom\', self.odom_callback, 10)\r\n        \r\n        # State tracking\r\n        self.current_pos_x = 0.0\r\n        self.current_vel_x = 0.0\r\n    \r\n    def odom_callback(self, msg):\r\n        self.current_pos_x = msg.pose.pose.position.x\r\n        self.current_vel_x = msg.twist.twist.linear.x\n'})}),"\n",(0,i.jsx)(e.h2,{id:"\u2139\ufe0f-sim-to-real-transfer-\u2139\ufe0f",children:"\u2139\ufe0f Sim-to-Real Transfer \u2139\ufe0f"}),"\n",(0,i.jsx)(e.h3,{id:"-domain-randomization-",children:"\ud83e\udd16 Domain Randomization \ud83e\udd16"}),"\n",(0,i.jsx)(e.p,{children:"Domain randomization helps bridge the sim-to-real gap by training models on varied simulated environments:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import random\r\nimport numpy as np\r\n\r\nclass DomainRandomizer:\r\n    def __init__(self):\r\n        # Define parameter ranges for randomization\r\n        self.params = {\r\n            # Physics parameters\r\n            'gravity_range': [9.7, 9.9],\r\n            'friction_range': [0.1, 1.5],\r\n            'mass_variance': 0.1,  # \xb110% mass variation\r\n            \r\n            # Sensor parameters\r\n            'camera_noise_range': [0.001, 0.05],\r\n            'lidar_noise_range': [0.005, 0.02],\r\n            \r\n            # Environment parameters\r\n            'lighting_min_intensity': 0.1,\r\n            'lighting_max_intensity': 1.0,\r\n            'texture_variation': True\r\n        }\r\n    \r\n    def randomize_environment(self, sdf_template):\r\n        \"\"\"Apply randomizations to environment parameters\"\"\"\r\n        gravity = random.uniform(*self.params['gravity_range'])\r\n        friction = random.uniform(*self.params['friction_range'])\r\n        \r\n        # Modify SDF template with randomized parameters\r\n        sdf_modified = sdf_template.replace('{GRAVITY_CONSTANT}', str(gravity))\r\n        sdf_modified = sdf_modified.replace('{FRICTION_COEFF}', str(friction))\r\n        \r\n        # Add more randomizations as needed\r\n        return sdf_modified\r\n    \r\n    def randomize_robot_properties(self, urdf_model):\r\n        \"\"\"Apply randomizations to robot model properties\"\"\"\r\n        # Randomize mass within variance\r\n        mass_multiplier = 1.0 + random.uniform(-self.params['mass_variance'], self.params['mass_variance'])\r\n        \r\n        # In a real implementation, this would modify URDF mass values\r\n        # This is a simplified example\r\n        modified_urdf = urdf_model.replace('mass value=\"1.0\"', f'mass value=\"{1.0 * mass_multiplier}\"')\r\n        \r\n        # Add noise to inertial parameters\r\n        # Modify sensor parameters\r\n        # Adjust joint limits slightly\r\n        \r\n        return modified_urdf\r\n    \r\n    def apply_texture_randomization(self, model_path):\r\n        \"\"\"Apply texture and color randomization to improve visual domain transfer\"\"\"\r\n        # This would modify material properties in the model\r\n        # Change colors within plausible ranges\r\n        # Apply different textures from a library\r\n        pass\n"})}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-system-identification-for-parameter-tuning-\u2139\ufe0f",children:"\u2139\ufe0f System Identification for Parameter Tuning \u2139\ufe0f"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\r\nfrom scipy.optimize import minimize\r\nimport matplotlib.pyplot as plt\r\n\r\nclass SystemIdentifier:\r\n    def __init__(self, robot_model):\r\n        self.robot_model = robot_model\r\n        self.sim_params = {}\r\n        self.real_params = {}\r\n    \r\n    def collect_trajectory_data(self, sim_robot, real_robot, trajectories):\r\n        """Collect trajectory data from both simulation and real robot"""\r\n        sim_data = []\r\n        real_data = []\r\n        \r\n        for trajectory in trajectories:\r\n            # Execute same trajectory in both sim and real\r\n            sim_result = self.execute_trajectory(sim_robot, trajectory)\r\n            real_result = self.execute_trajectory(real_robot, trajectory)\r\n            \r\n            sim_data.append(sim_result)\r\n            real_data.append(real_result)\r\n        \r\n        return sim_data, real_data\r\n    \r\n    def objective_function(self, params):\r\n        """Objective function to minimize sim-to-real discrepancy"""\r\n        # Set simulation parameters\r\n        self.set_simulation_params(params)\r\n        \r\n        # Collect data with current parameters\r\n        sim_data, real_data = self.collect_trajectory_data(self.sim_robot, self.real_robot, self.trajectories)\r\n        \r\n        # Calculate discrepancy\r\n        error = 0\r\n        for sim_traj, real_traj in zip(sim_data, real_data):\r\n            error += np.sum((np.array(sim_traj) - np.array(real_traj))**2)\r\n        \r\n        return error\r\n    \r\n    def tune_parameters(self, initial_params, bounds):\r\n        """Tune simulation parameters to match real robot behavior"""\r\n        result = minimize(\r\n            self.objective_function,\r\n            initial_params,\r\n            bounds=bounds,\r\n            method=\'L-BFGS-B\'\r\n        )\r\n        \r\n        self.best_params = result.x\r\n        self.get_logger().info(f\'Optimized parameters: {self.best_params}\')\r\n        \r\n        return result.x\r\n    \r\n    def validate_transfer(self, policy):\r\n        """Validate that a policy trained in simulation works on the real robot"""\r\n        # Test performance in simulation\r\n        sim_score = self.evaluate_policy(policy, self.sim_robot)\r\n        \r\n        # Test performance on real robot\r\n        real_score = self.evaluate_policy(policy, self.real_robot)\r\n        \r\n        # Calculate sim-to-real gap\r\n        gap = abs(sim_score - real_score) / max(abs(sim_score), abs(real_score), 1e-6)\r\n        \r\n        self.get_logger().info(f\'Sim-to-real gap: {gap:.3f}\')\r\n        return gap < 0.1  # Return True if gap is below threshold\n'})}),"\n",(0,i.jsx)(e.h2,{id:"-performance-optimization-",children:"\ud83d\udcc8 Performance Optimization \ud83d\udcc8"}),"\n",(0,i.jsx)(e.h3,{id:"-simulation-performance-strategies-",children:"\ud83c\udfae Simulation Performance Strategies \ud83c\udfae"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class OptimizedSimulation(Node):\r\n    def __init__(self):\r\n        super().__init__(\'optimized_simulation\')\r\n        \r\n        # Use efficient data structures and algorithms\r\n        self.collision_grid = {}  # Spatial hash for collision detection\r\n        \r\n        # Optimize rendering\r\n        self.rendering_enabled = True\r\n        self.display_framerate = 60  # Target display framerate\r\n        \r\n        # Optimize physics\r\n        self.physics_framerate = 1000  # Physics update rate\r\n        self.max_substeps = 10  # Max substeps for stability\r\n        \r\n        # Use efficient communication patterns\r\n        self.compression_enabled = False  # Consider compressing large sensor data\r\n        self.throttling_active = True  # Throttle non-critical updates\r\n        \r\n        # Memory management\r\n        self.message_pool = []  # Reuse message objects to reduce allocation\r\n        self.buffer_size = 1000  # Size of message pool\r\n        \r\n        self.setup_optimized_publishers()\r\n    \r\n    def setup_optimized_publishers(self):\r\n        """Set up publishers with optimized QoS profiles"""\r\n        \r\n        # High-frequency sensor data - use best-effort, keep last\r\n        sensor_qos = QoSProfile(\r\n            depth=1,\r\n            reliability=ReliabilityPolicy.BEST_EFFORT,\r\n            durability=DurabilityPolicy.VOLATILE,\r\n            history=HistoryPolicy.KEEP_LAST\r\n        )\r\n        \r\n        self.lidar_pub = self.create_publisher(LaserScan, \'scan\', sensor_qos)\r\n        \r\n        # Critical control data - use reliable, keep last\r\n        control_qos = QoSProfile(\r\n            depth=10,\r\n            reliability=ReliabilityPolicy.RELIABLE,\r\n            durability=DurabilityPolicy.VOLATILE,\r\n            history=HistoryPolicy.KEEP_LAST\r\n        )\r\n        \r\n        self.cmd_pub = self.create_publisher(Twist, \'cmd_vel\', control_qos)\r\n    \r\n    def optimize_physics_step(self):\r\n        """Optimize physics calculation"""\r\n        # Use fixed timestep for consistency\r\n        dt = 1.0 / self.physics_framerate\r\n        \r\n        # Limit substeps to prevent performance degradation\r\n        if dt > self.max_substeps * 0.001:\r\n            dt = self.max_substeps * 0.001\r\n        \r\n        # Perform physics update\r\n        self.update_physics(dt)\r\n        \r\n        # Update rendering less frequently than physics\r\n        if self.should_render():\r\n            self.render_scene()\r\n    \r\n    def should_render(self):\r\n        """Determine if rendering should occur this frame"""\r\n        current_time = time.time()\r\n        if hasattr(self, \'last_render_time\'):\r\n            elapsed = current_time - self.last_render_time\r\n            target_interval = 1.0 / self.display_framerate\r\n            if elapsed >= target_interval:\r\n                self.last_render_time = current_time\r\n                return True\r\n        else:\r\n            self.last_render_time = current_time\r\n            return True\r\n        return False\r\n    \r\n    def reuse_message_objects(self):\r\n        """Reuse message objects to reduce garbage collection pressure"""\r\n        if len(self.message_pool) > 0:\r\n            msg = self.message_pool.pop()\r\n        else:\r\n            msg = LaserScan()  # Create new if pool is empty\r\n        \r\n        # Use the message...\r\n        # When done, return to pool instead of deleting\r\n        self.return_to_pool(msg)\r\n    \r\n    def return_to_pool(self, msg):\r\n        """Return message object to pool for reuse"""\r\n        if len(self.message_pool) < self.buffer_size:\r\n            # Reset message to default state before returning to pool\r\n            msg.ranges = []\r\n            msg.intensities = []\r\n            self.message_pool.append(msg)\n'})}),"\n",(0,i.jsx)(e.h2,{id:"-chapter-summary-",children:"\ud83d\udcdd Chapter Summary \ud83d\udcdd"}),"\n",(0,i.jsx)(e.p,{children:"Simulation environments are a cornerstone of Physical AI development, providing safe, cost-effective, and controllable platforms for testing and training robotic systems. Key points from this chapter:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Gazebo"}),": Advanced physics simulation with realistic collision and sensor modeling"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Unity"}),": High-fidelity rendering and VR/AR capabilities for visual realism"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"URDF/SDF"}),": Critical for robot and environment modeling"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sensor Simulation"}),": Accurate modeling of real-world sensors with noise and characteristics"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Physics Simulation"}),": Proper parameterization for realistic interactions"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Digital Twin Creation"}),": Environment design for effective training"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"ROS 2 Integration"}),": Bridging simulation and real-world control"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Sim-to-Real Transfer"}),": Techniques to minimize the reality gap"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Performance Optimization"}),": Efficient simulation execution"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Domain Randomization"}),": Techniques to improve sim-to-real transfer"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"The combination of accurate physics modeling, realistic sensor simulation, and proper domain randomization enables robots to learn in simulation and transfer their knowledge to real-world applications with minimal adaptation required."}),"\n",(0,i.jsx)(e.h2,{id:"-knowledge-check-",children:"\ud83e\udd14 Knowledge Check \ud83e\udd14"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"Explain the differences between ROS 1 and ROS 2 communication architectures and their impact on simulation."}),"\n",(0,i.jsx)(e.li,{children:"Compare Gazebo and Unity for robotics simulation. When would you choose each?"}),"\n",(0,i.jsx)(e.li,{children:"What are the key components of a Gazebo world file? Create a simple example."}),"\n",(0,i.jsx)(e.li,{children:"How do you implement sensor fusion simulation with multiple sensor types?"}),"\n",(0,i.jsx)(e.li,{children:"What techniques can be used to reduce the sim-to-real gap?"}),"\n",(0,i.jsx)(e.li,{children:"Explain Quality of Service (QoS) profiles in ROS 2 and their importance for simulation."}),"\n",(0,i.jsx)(e.li,{children:"What are the trade-offs between simulation fidelity and computational performance?"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"\u2139\ufe0f-practical-exercise-\u2139\ufe0f",children:"\u2139\ufe0f Practical Exercise \u2139\ufe0f"}),"\n",(0,i.jsx)(e.p,{children:"Create a complete simulation environment with:"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"A robot model with LiDAR, camera, and IMU sensors"}),"\n",(0,i.jsx)(e.li,{children:"A structured environment with obstacles"}),"\n",(0,i.jsx)(e.li,{children:"ROS 2 nodes for controlling the robot and processing sensor data"}),"\n",(0,i.jsx)(e.li,{children:"Performance monitoring tools"}),"\n",(0,i.jsx)(e.li,{children:"Domain randomization capabilities"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"-discussion-questions-",children:"\ud83d\udcac Discussion Questions \ud83d\udcac"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"How might you design a simulation environment specifically for training humanoid robots to walk on uneven terrain?"}),"\n",(0,i.jsx)(e.li,{children:"What are the challenges of simulating soft-body interactions for robotic manipulation?"}),"\n",(0,i.jsx)(e.li,{children:"How can you validate that your simulation accurately represents real-world physics?"}),"\n",(0,i.jsx)(e.li,{children:"What role does cloud computing play in large-scale robotics simulation?"}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>a,x:()=>o});var i=r(6540);const s={},t=i.createContext(s);function a(n){const e=i.useContext(t);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:a(n.components),i.createElement(t.Provider,{value:e},n.children)}}}]);